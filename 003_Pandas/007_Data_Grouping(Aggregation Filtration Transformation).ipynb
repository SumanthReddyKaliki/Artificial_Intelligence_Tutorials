{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "One of the most fundamental tasks during a data analysis involves splitting data into independent groups before performing a calculation on each group. This methodology has been around for quite some time but has more recently been referred to as split-apply-combine. This chapter covers the powerful groupby method, which allows you to group your data in any way imaginable and apply any type of function independently to each group before returning a single dataset.\n",
    "\n",
    "**Note**\n",
    "\n",
    "Hadley Wickham coined the term split-apply-combine to describe the common data analysis pattern of breaking up data into independent manageable chunks, independently applying functions to these chunks, and then combining the results back together. More details can be found in his paper (http://bit.ly/2isFuL9).\n",
    "\n",
    "Before we get started with the recipes, we will need to know just a little terminology. All basic groupby operations have grouping columns, and each unique combination of values in these columns represents an independent grouping of the data. The syntax looks as follows:\n",
    "\n",
    "`df.groupby(['list', 'of', 'grouping', 'columns'])\n",
    "df.groupby('single_column')  # when grouping by a single column`\n",
    "\n",
    "The result of this operation returns a groupby object. It is this groupby object that will be the engine that drives all the calculations for this entire chapter. Pandas actually does very little when creating this groupby object, merely validating that grouping is possible. You will have to chain methods on this groupby object in order to unleash its powers.\n",
    "\n",
    "**Note**\n",
    "\n",
    "Technically, the result of the operation will either be a DataFrameGroupBy or SeriesGroupBy but for simplicity, it will be referred to as the groupby object for the entire chapter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining an aggregation\n",
    "\n",
    "The most common use of the groupby method is to perform an aggregation. What actually is an aggregation? In our data analysis world, an aggregation takes place when a sequence of many inputs get summarized or combined into a single value output. For example, summing up all the values of a column or finding its maximum are common aggregations applied on a single sequence of data. An aggregation simply takes many values and converts them down to a single value.\n",
    "\n",
    "In addition to the grouping columns defined during the introduction, most aggregations have two other components, the aggregating columns and aggregating functions. The aggregating columns are those whose values will be aggregated. `The aggregating functions define how the aggregation takes place. Major aggregation functions include sum, min, max, mean, count, variance, std, and so on.`\n",
    "\n",
    "### Getting ready\n",
    "\n",
    "In this recipe, we examine the flights dataset and perform the simplest possible aggregation involving only a single grouping column, a single aggregating column, and a single aggregating function. `We will find the average arrival delay for each airline. Pandas has quite a few different syntaxes to produce an aggregation and this recipe covers them.`\n",
    "\n",
    "### How to do it...\n",
    "\n",
    "Read in the flights dataset, and define the grouping columns (AIRLINE), aggregating columns (ARR_DELAY), and aggregating functions (mean):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>ORG_AIR</th>\n",
       "      <th>DEST_AIR</th>\n",
       "      <th>SCHED_DEP</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DIST</th>\n",
       "      <th>SCHED_ARR</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>SLC</td>\n",
       "      <td>1625</td>\n",
       "      <td>58.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>590</td>\n",
       "      <td>1905</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>UA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>IAD</td>\n",
       "      <td>823</td>\n",
       "      <td>7.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1452</td>\n",
       "      <td>1333</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>MQ</td>\n",
       "      <td>DFW</td>\n",
       "      <td>VPS</td>\n",
       "      <td>1305</td>\n",
       "      <td>36.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>641</td>\n",
       "      <td>1453</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>DCA</td>\n",
       "      <td>1555</td>\n",
       "      <td>7.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1192</td>\n",
       "      <td>1935</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1720</td>\n",
       "      <td>48.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1363</td>\n",
       "      <td>2225</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MONTH  DAY  WEEKDAY AIRLINE ORG_AIR DEST_AIR  SCHED_DEP  DEP_DELAY  \\\n",
       "0      1    1        4      WN     LAX      SLC       1625       58.0   \n",
       "1      1    1        4      UA     DEN      IAD        823        7.0   \n",
       "2      1    1        4      MQ     DFW      VPS       1305       36.0   \n",
       "3      1    1        4      AA     DFW      DCA       1555        7.0   \n",
       "4      1    1        4      WN     LAX      MCI       1720       48.0   \n",
       "\n",
       "   AIR_TIME  DIST  SCHED_ARR  ARR_DELAY  DIVERTED  CANCELLED  \n",
       "0      94.0   590       1905       65.0         0          0  \n",
       "1     154.0  1452       1333      -13.0         0          0  \n",
       "2      85.0   641       1453       35.0         0          0  \n",
       "3     126.0  1192       1935       -7.0         0          0  \n",
       "4     166.0  1363       2225       39.0         0          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights = pd.read_csv('data/flights.csv')\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place the grouping column in the groupby method and then call the agg method with a dictionary pairing the aggregating column with its aggregating function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIRLINE\n",
       "AA    5.542661\n",
       "AS   -0.833333\n",
       "B6    8.692593\n",
       "DL    0.339691\n",
       "EV    7.034580\n",
       "Name: ARR_DELAY, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.groupby('AIRLINE')['ARR_DELAY'].agg('mean').head() #Average airline delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you may place the aggregating column in the indexing operator and then pass the aggregating function as a string to agg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARR_DELAY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIRLINE</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <td>5.542661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AS</th>\n",
       "      <td>-0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B6</th>\n",
       "      <td>8.692593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DL</th>\n",
       "      <td>0.339691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EV</th>\n",
       "      <td>7.034580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ARR_DELAY\n",
       "AIRLINE           \n",
       "AA        5.542661\n",
       "AS       -0.833333\n",
       "B6        8.692593\n",
       "DL        0.339691\n",
       "EV        7.034580"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.groupby('AIRLINE').agg({'ARR_DELAY':'mean'}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The string names used in the previous step are a convenience pandas offers you to refer to a particular aggregation function. You can pass any aggregating function directly to the agg method such as the NumPy mean function. The output is the same as the previous step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIRLINE\n",
       "AA    5.542661\n",
       "AS   -0.833333\n",
       "B6    8.692593\n",
       "DL    0.339691\n",
       "EV    7.034580\n",
       "Name: ARR_DELAY, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.groupby('AIRLINE')['ARR_DELAY'].agg(np.mean).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible to skip the agg method altogether in this case and use the mean method directly. This output is also the same as step 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIRLINE\n",
       "AA    5.542661\n",
       "AS   -0.833333\n",
       "B6    8.692593\n",
       "DL    0.339691\n",
       "EV    7.034580\n",
       "Name: ARR_DELAY, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.groupby('AIRLINE')['ARR_DELAY'].mean().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it works...\n",
    "\n",
    "The syntax for the groupby method is not as straightforward as other methods. Let's intercept the chain of methods in step 2 by storing the result of the groupby method as its own variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.groupby.generic.DataFrameGroupBy"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = flights.groupby('AIRLINE')\n",
    "type(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "A completely new intermediate object is first produced with its own distinct attributes and methods. No calculations take place at this stage. Pandas merely validates the grouping columns. This groupby object has an agg method to perform aggregations. One of the ways to use this method is to pass it a dictionary mapping the aggregating column to the aggregating function, as done in step 2.\n",
    "\n",
    "There are several different flavors of syntax that produce a similar result, with step 3 showing an alternative. Instead of identifying the aggregating column in the dictionary, place it inside the indexing operator just as if you were selecting it as a column from a DataFrame. The function string name is then passed as a scalar to the agg method.\n",
    "\n",
    "You may pass any aggregating function to the agg method. Pandas allows you to use the string names for simplicity but you may also explicitly call an aggregating function as done in step 4. NumPy provides many functions that aggregate values.\n",
    "\n",
    "Step 5 shows one last syntax flavor. When you are only applying a single aggregating function as in this example, you can often call it directly as a method on the groupby object itself without agg. Not all aggregation functions have a method equivalent but many basic ones do. The following is a list of several aggregating functions that may be passed as a string to agg or chained directly as a method to the groupby object:\n",
    "\n",
    "`min     max    mean    median    sum    count    std    var   \n",
    "size    describe    nunique     idxmin     idxmax`\n",
    "\n",
    "### There's more...\n",
    "\n",
    "If you do not use an aggregating function with agg, pandas raises an exception. For instance, let's see what happens when we apply the square root function to each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumanth\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must produce aggregated value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mflights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAIRLINE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mARR_DELAY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:292\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_agg_general(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_agg_general(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;66;03m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;66;03m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n\u001b[0;32m    297\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_named(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:325\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: func(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    324\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\n\u001b[1;32m--> 325\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m res \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_constructor(result, name\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:849\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39m_values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    843\u001b[0m     \u001b[38;5;66;03m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;66;03m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;66;03m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;66;03m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[0;32m    847\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 849\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mconstruct_array_type()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:882\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m    878\u001b[0m res \u001b[38;5;241m=\u001b[39m extract_result(res)\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m     \u001b[43mcheck_result_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     initialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    885\u001b[0m result[i] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:89\u001b[0m, in \u001b[0;36mcheck_result_array\u001b[1;34m(obj, dtype)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;66;03m# If it is object dtype, the function can be a reduction/aggregation\u001b[39;00m\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;66;03m#  and still return an ndarray e.g. test_agg_over_numpy_arrays\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust produce aggregated value\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Must produce aggregated value"
     ]
    }
   ],
   "source": [
    "flights.groupby('AIRLINE')['ARR_DELAY'].agg(np.sqrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping and aggregating with multiple columns and functions\n",
    "It is possible to do grouping and aggregating with multiple columns. The syntax is only slightly different than it is for grouping and aggregating with a single column. As usual with any kind of grouping operation, it helps to identify the three components: the grouping columns, aggregating columns, and aggregating functions.\n",
    "\n",
    "### Getting ready\n",
    "\n",
    "In this recipe, we showcase the flexibility of the groupby DataFrame method by answering the following queries:\n",
    "\n",
    "Finding the number of cancelled flights for every airline per weekday\n",
    "\n",
    "Finding the number and percentage of cancelled and diverted flights for every airline per weekday\n",
    "\n",
    "For each origin and destination, finding the total number of flights, the number and percentage of cancelled flights, and the average and variance of the airtime\n",
    "\n",
    "### How to do it...\n",
    "\n",
    "Read in the flights dataset, and answer the first query by defining the grouping columns (AIRLINE, WEEKDAY), the aggregating column (CANCELLED), and the aggregating function (sum):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>ORG_AIR</th>\n",
       "      <th>DEST_AIR</th>\n",
       "      <th>SCHED_DEP</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DIST</th>\n",
       "      <th>SCHED_ARR</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>SLC</td>\n",
       "      <td>1625</td>\n",
       "      <td>58.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>590</td>\n",
       "      <td>1905</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>UA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>IAD</td>\n",
       "      <td>823</td>\n",
       "      <td>7.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1452</td>\n",
       "      <td>1333</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>MQ</td>\n",
       "      <td>DFW</td>\n",
       "      <td>VPS</td>\n",
       "      <td>1305</td>\n",
       "      <td>36.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>641</td>\n",
       "      <td>1453</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>DCA</td>\n",
       "      <td>1555</td>\n",
       "      <td>7.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1192</td>\n",
       "      <td>1935</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1720</td>\n",
       "      <td>48.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1363</td>\n",
       "      <td>2225</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MONTH  DAY  WEEKDAY AIRLINE ORG_AIR DEST_AIR  SCHED_DEP  DEP_DELAY  \\\n",
       "0      1    1        4      WN     LAX      SLC       1625       58.0   \n",
       "1      1    1        4      UA     DEN      IAD        823        7.0   \n",
       "2      1    1        4      MQ     DFW      VPS       1305       36.0   \n",
       "3      1    1        4      AA     DFW      DCA       1555        7.0   \n",
       "4      1    1        4      WN     LAX      MCI       1720       48.0   \n",
       "\n",
       "   AIR_TIME  DIST  SCHED_ARR  ARR_DELAY  DIVERTED  CANCELLED  \n",
       "0      94.0   590       1905       65.0         0          0  \n",
       "1     154.0  1452       1333      -13.0         0          0  \n",
       "2      85.0   641       1453       35.0         0          0  \n",
       "3     126.0  1192       1935       -7.0         0          0  \n",
       "4     166.0  1363       2225       39.0         0          0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights = pd.read_csv('data/flights.csv')\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIRLINE  WEEKDAY\n",
       "AA       1          41\n",
       "         2           9\n",
       "         3          16\n",
       "         4          20\n",
       "         5          18\n",
       "         6          21\n",
       "         7          29\n",
       "Name: CANCELLED, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of cancelled flights for every airline per day weekday\n",
    "flights.groupby(['AIRLINE', 'WEEKDAY'])['CANCELLED'].agg('sum').head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the second query by using a list for each pair of grouping and aggregating columns. Also, use a list for the aggregating functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">CANCELLED</th>\n",
       "      <th colspan=\"2\" halign=\"left\">DIVERTED</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">AA</th>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>0.032106</td>\n",
       "      <td>6</td>\n",
       "      <td>0.004699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.007341</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.011949</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>9</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>0.021837</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                CANCELLED           DIVERTED          \n",
       "                      sum      mean      sum      mean\n",
       "AIRLINE WEEKDAY                                       \n",
       "AA      1              41  0.032106        6  0.004699\n",
       "        2               9  0.007341        2  0.001631\n",
       "        3              16  0.011949        2  0.001494\n",
       "        4              20  0.015004        5  0.003751\n",
       "        5              18  0.014151        1  0.000786\n",
       "        6              21  0.018667        9  0.008000\n",
       "        7              29  0.021837        1  0.000753"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the number and percentage of cancelled and diverted flights for every airline per weekday\n",
    "#First we groupby on airline and weekday then select columns cancelled and diverted. After that calculate sum and mean for each column\n",
    "flights.groupby(['AIRLINE', 'WEEKDAY'])[['CANCELLED', 'DIVERTED']].agg(['sum', 'mean']).head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the third query using a dictionary in the agg method to map specific aggregating columns to specific aggregating functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">CANCELLED</th>\n",
       "      <th colspan=\"2\" halign=\"left\">AIR_TIME</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG_AIR</th>\n",
       "      <th>DEST_AIR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ATL</th>\n",
       "      <th>ABE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>96.387097</td>\n",
       "      <td>45.778495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABQ</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>170.500000</td>\n",
       "      <td>87.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABY</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>28.578947</td>\n",
       "      <td>6.590643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACY</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>91.333333</td>\n",
       "      <td>11.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AEX</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>78.725000</td>\n",
       "      <td>47.332692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 CANCELLED              AIR_TIME           \n",
       "                       sum mean size        mean        var\n",
       "ORG_AIR DEST_AIR                                           \n",
       "ATL     ABE              0  0.0   31   96.387097  45.778495\n",
       "        ABQ              0  0.0   16  170.500000  87.866667\n",
       "        ABY              0  0.0   19   28.578947   6.590643\n",
       "        ACY              0  0.0    6   91.333333  11.466667\n",
       "        AEX              0  0.0   40   78.725000  47.332692"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each origin to destination flight, find the total number of flights, \n",
    "# the number and percentage of cancelled flights and the average and variance of the airtime. \n",
    "flights.groupby(['ORG_AIR', 'DEST_AIR']).agg({'CANCELLED': ['sum', 'mean', 'size'], \n",
    "                                              'AIR_TIME':['mean', 'var']}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works...\n",
    "\n",
    "To group by multiple columns as in step 1, we pass a list of the string names to the groupby method. Each unique combination of AIRLINE and WEEKDAY forms an independent group. Within each of these groups, the sum of the cancelled flights is found and then returned as a Series.\n",
    "\n",
    "Step 2, again groups by both AIRLINE and WEEKDAY, but this time aggregates two columns. It applies each of the two aggregation functions, sum and mean, to each column resulting in four returned columns per group.\n",
    "\n",
    "Step 3 goes even further, and uses a dictionary to map specific aggregating columns to different aggregating functions. Notice that the size aggregating function returns the total number of rows per group. This is different than the count aggregating function, which returns the number of non-missing values per group.\n",
    "\n",
    "### There's more...\n",
    "\n",
    "There are a few main flavors of syntax that you will encounter when performing an aggregation. The following four blocks of pseudocode summarize the main ways you can perform an aggregation with the groupby method:\n",
    "\n",
    "Using agg with a dictionary is the most flexible and allows you to specify the aggregating function for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby(['grouping', 'columns']) \\\n",
    "#      .agg({'agg_cols1':['list', 'of', 'functions'], \n",
    "#            'agg_cols2':['other', 'functions']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using agg with a list of aggregating functions applies each of the functions to each of the aggregating columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby(['grouping', 'columns'])['aggregating', 'columns'] \\\n",
    "#      .agg([aggregating, functions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directly using a method following the aggregating columns instead of agg, applies just that method to each aggregating column. This way does not allow for multiple aggregating functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby(['grouping', 'columns'])['aggregating', 'columns'] \\\n",
    "#      .aggregating_method()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not specify the aggregating columns, then the aggregating method will be applied to all the non-grouping columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby(['grouping', 'columns']).aggregating_method()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceding four code blocks it is possible to substitute a string for any of the lists when grouping or aggregating by a single column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing the MultiIndex after grouping\n",
    "Inevitably, when using groupby, you will likely create a MultiIndex in the columns or rows or both. DataFrames with MultiIndexes are more difficult to navigate and occasionally have confusing column names as well.\n",
    "\n",
    "### Getting ready\n",
    "\n",
    "In this recipe, we perform an aggregation with the groupby method to create a DataFrame with a MultiIndex for the rows and columns and then manipulate it so that the index is a single level and the column names are descriptive.\n",
    "\n",
    "### How to do it...\n",
    "\n",
    "`Read in the flights dataset; write a statement to find the total and average miles flown; and the maximum and minimum arrival delay for each airline for each weekday:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>ORG_AIR</th>\n",
       "      <th>DEST_AIR</th>\n",
       "      <th>SCHED_DEP</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DIST</th>\n",
       "      <th>SCHED_ARR</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>SLC</td>\n",
       "      <td>1625</td>\n",
       "      <td>58.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>590</td>\n",
       "      <td>1905</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>UA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>IAD</td>\n",
       "      <td>823</td>\n",
       "      <td>7.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1452</td>\n",
       "      <td>1333</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>MQ</td>\n",
       "      <td>DFW</td>\n",
       "      <td>VPS</td>\n",
       "      <td>1305</td>\n",
       "      <td>36.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>641</td>\n",
       "      <td>1453</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>DCA</td>\n",
       "      <td>1555</td>\n",
       "      <td>7.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1192</td>\n",
       "      <td>1935</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1720</td>\n",
       "      <td>48.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1363</td>\n",
       "      <td>2225</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MONTH  DAY  WEEKDAY AIRLINE ORG_AIR DEST_AIR  SCHED_DEP  DEP_DELAY  \\\n",
       "0      1    1        4      WN     LAX      SLC       1625       58.0   \n",
       "1      1    1        4      UA     DEN      IAD        823        7.0   \n",
       "2      1    1        4      MQ     DFW      VPS       1305       36.0   \n",
       "3      1    1        4      AA     DFW      DCA       1555        7.0   \n",
       "4      1    1        4      WN     LAX      MCI       1720       48.0   \n",
       "\n",
       "   AIR_TIME  DIST  SCHED_ARR  ARR_DELAY  DIVERTED  CANCELLED  \n",
       "0      94.0   590       1905       65.0         0          0  \n",
       "1     154.0  1452       1333      -13.0         0          0  \n",
       "2      85.0   641       1453       35.0         0          0  \n",
       "3     126.0  1192       1935       -7.0         0          0  \n",
       "4     166.0  1363       2225       39.0         0          0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights = pd.read_csv('data/flights.csv')\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">DIST</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ARR_DELAY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AA</th>\n",
       "      <th>1</th>\n",
       "      <td>1455386</td>\n",
       "      <td>1139</td>\n",
       "      <td>-60</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1358256</td>\n",
       "      <td>1107</td>\n",
       "      <td>-52</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1496665</td>\n",
       "      <td>1117</td>\n",
       "      <td>-45</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1452394</td>\n",
       "      <td>1089</td>\n",
       "      <td>-46</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1427749</td>\n",
       "      <td>1122</td>\n",
       "      <td>-41</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DIST       ARR_DELAY     \n",
       "                     sum  mean       min  max\n",
       "AIRLINE WEEKDAY                              \n",
       "AA      1        1455386  1139       -60  551\n",
       "        2        1358256  1107       -52  725\n",
       "        3        1496665  1117       -45  473\n",
       "        4        1452394  1089       -46  349\n",
       "        5        1427749  1122       -41  732"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_info = flights.groupby(['AIRLINE', 'WEEKDAY'])\\\n",
    "                      .agg({'DIST':['sum', 'mean'], \n",
    "                                    'ARR_DELAY':['min', 'max']}).astype(int)\n",
    "airline_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the rows and columns are labeled by a MultiIndex with two levels. Let's squash it down to just a single level. To address the columns, we use the MultiIndex method, get_level_values. Let's display the output of each level and then concatenate both levels before setting it as the new column values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DIST', 'DIST', 'ARR_DELAY', 'ARR_DELAY'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level0 = airline_info.columns.get_level_values(0)\n",
    "level0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sum', 'mean', 'min', 'max'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level1 = airline_info.columns.get_level_values(1)\n",
    "level1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_info.columns = level0 + '_' + level1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>DIST_sum</th>\n",
       "      <th>DIST_mean</th>\n",
       "      <th>ARR_DELAY_min</th>\n",
       "      <th>ARR_DELAY_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">AA</th>\n",
       "      <th>1</th>\n",
       "      <td>1455386</td>\n",
       "      <td>1139</td>\n",
       "      <td>-60</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1358256</td>\n",
       "      <td>1107</td>\n",
       "      <td>-52</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1496665</td>\n",
       "      <td>1117</td>\n",
       "      <td>-45</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1452394</td>\n",
       "      <td>1089</td>\n",
       "      <td>-46</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1427749</td>\n",
       "      <td>1122</td>\n",
       "      <td>-41</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1265340</td>\n",
       "      <td>1124</td>\n",
       "      <td>-50</td>\n",
       "      <td>858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1461906</td>\n",
       "      <td>1100</td>\n",
       "      <td>-49</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DIST_sum  DIST_mean  ARR_DELAY_min  ARR_DELAY_max\n",
       "AIRLINE WEEKDAY                                                   \n",
       "AA      1         1455386       1139            -60            551\n",
       "        2         1358256       1107            -52            725\n",
       "        3         1496665       1117            -45            473\n",
       "        4         1452394       1089            -46            349\n",
       "        5         1427749       1122            -41            732\n",
       "        6         1265340       1124            -50            858\n",
       "        7         1461906       1100            -49            626"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_info.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return the row labels to a single level with reset_index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>DIST_sum</th>\n",
       "      <th>DIST_mean</th>\n",
       "      <th>ARR_DELAY_min</th>\n",
       "      <th>ARR_DELAY_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>1</td>\n",
       "      <td>1455386</td>\n",
       "      <td>1139</td>\n",
       "      <td>-60</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>2</td>\n",
       "      <td>1358256</td>\n",
       "      <td>1107</td>\n",
       "      <td>-52</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA</td>\n",
       "      <td>3</td>\n",
       "      <td>1496665</td>\n",
       "      <td>1117</td>\n",
       "      <td>-45</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA</td>\n",
       "      <td>4</td>\n",
       "      <td>1452394</td>\n",
       "      <td>1089</td>\n",
       "      <td>-46</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA</td>\n",
       "      <td>5</td>\n",
       "      <td>1427749</td>\n",
       "      <td>1122</td>\n",
       "      <td>-41</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AA</td>\n",
       "      <td>6</td>\n",
       "      <td>1265340</td>\n",
       "      <td>1124</td>\n",
       "      <td>-50</td>\n",
       "      <td>858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AA</td>\n",
       "      <td>7</td>\n",
       "      <td>1461906</td>\n",
       "      <td>1100</td>\n",
       "      <td>-49</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AIRLINE  WEEKDAY  DIST_sum  DIST_mean  ARR_DELAY_min  ARR_DELAY_max\n",
       "0      AA        1   1455386       1139            -60            551\n",
       "1      AA        2   1358256       1107            -52            725\n",
       "2      AA        3   1496665       1117            -45            473\n",
       "3      AA        4   1452394       1089            -46            349\n",
       "4      AA        5   1427749       1122            -41            732\n",
       "5      AA        6   1265340       1124            -50            858\n",
       "6      AA        7   1461906       1100            -49            626"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_info.reset_index().head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works...\n",
    "\n",
    "When using the agg method to perform an aggregation on multiple columns, pandas creates an index object with two levels. The aggregating columns become the top level and the aggregating functions become the bottom level. Pandas displays MultiIndex levels differently than single-level columns. Except for the innermost levels, repeated index values do not get displayed on the screen. You can inspect the DataFrame from step 1 to verify this. For instance, the DIST column shows up only once but it refers to both of the first two columns.\n",
    "\n",
    "**Note**\n",
    "\n",
    "The innermost MultiIndex level is the one closest to the data. This would be the bottom-most column level and the right-most index level.\n",
    "\n",
    "Step 2 defines new columns by first retrieving the underlying values of each of the levels with the MultiIndex method get_level_values. This method accepts an integer identifying the index level. They are numbered beginning with zero from the top/left. Indexes support vectorized operations, so we concatenate both levels together with a separating underscore. We assign these new values to the columns attribute.\n",
    "\n",
    "In step 3, we make both index levels as columns with reset_index. We could have concatenated the levels together like we did in step 2, but it makes more sense to keep them as separate columns.\n",
    "\n",
    "### There's more...\n",
    "\n",
    "By default, at the end of a groupby operation, pandas puts all of the grouping columns in the index. The as_index parameter in the groupby method can be set to False to avoid this behavior. You can chain the reset_index method after grouping to get the same effect as done in step 3. Let's see an example of this by finding the average distance traveled per flight from each airline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>DIST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>1114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS</td>\n",
       "      <td>1066.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B6</td>\n",
       "      <td>1772.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL</td>\n",
       "      <td>866.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EV</td>\n",
       "      <td>460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F9</td>\n",
       "      <td>970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HA</td>\n",
       "      <td>2615.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MQ</td>\n",
       "      <td>404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NK</td>\n",
       "      <td>1047.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OO</td>\n",
       "      <td>511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UA</td>\n",
       "      <td>1231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>US</td>\n",
       "      <td>1181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VX</td>\n",
       "      <td>1240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WN</td>\n",
       "      <td>810.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AIRLINE    DIST\n",
       "0       AA  1114.0\n",
       "1       AS  1066.0\n",
       "2       B6  1772.0\n",
       "3       DL   866.0\n",
       "4       EV   460.0\n",
       "5       F9   970.0\n",
       "6       HA  2615.0\n",
       "7       MQ   404.0\n",
       "8       NK  1047.0\n",
       "9       OO   511.0\n",
       "10      UA  1231.0\n",
       "11      US  1181.0\n",
       "12      VX  1240.0\n",
       "13      WN   810.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.groupby(['AIRLINE'], as_index=False)['DIST'].agg('mean').round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>DIST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WN</td>\n",
       "      <td>809.985626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UA</td>\n",
       "      <td>1230.918891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MQ</td>\n",
       "      <td>404.229041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA</td>\n",
       "      <td>1114.347865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F9</td>\n",
       "      <td>969.593014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EV</td>\n",
       "      <td>460.237453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OO</td>\n",
       "      <td>511.239375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NK</td>\n",
       "      <td>1047.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>US</td>\n",
       "      <td>1181.226625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AS</td>\n",
       "      <td>1065.884115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DL</td>\n",
       "      <td>866.448448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VX</td>\n",
       "      <td>1240.296073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B6</td>\n",
       "      <td>1771.882136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HA</td>\n",
       "      <td>2615.178571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AIRLINE         DIST\n",
       "0       WN   809.985626\n",
       "1       UA  1230.918891\n",
       "2       MQ   404.229041\n",
       "3       AA  1114.347865\n",
       "4       F9   969.593014\n",
       "5       EV   460.237453\n",
       "6       OO   511.239375\n",
       "7       NK  1047.428100\n",
       "8       US  1181.226625\n",
       "9       AS  1065.884115\n",
       "10      DL   866.448448\n",
       "11      VX  1240.296073\n",
       "12      B6  1771.882136\n",
       "13      HA  2615.178571"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.groupby(['AIRLINE'], as_index=False, sort=False)['DIST'].agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the order of the airlines in the previous result. By default, pandas sorts the grouping columns. The sort parameter exists within the groupby method and is defaulted to True. You may set it to False to keep the order of the grouping columns the same as how they are encountered in the dataset. You also get a small performance improvement by not sorting your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing an aggregation function\n",
    "Pandas provides a number of the most common aggregation functions for you to use with the groupby object. At some point, you will need to write your own customized user-defined functions that don't exist in pandas or NumPy.\n",
    "\n",
    "### Getting ready\n",
    "\n",
    "`In this recipe, we use the college dataset to calculate the mean and standard deviation of the undergraduate student population per state. We then use this information to find the maximum number of standard deviations from the mean that any single population value is per state.`\n",
    "\n",
    "### How to do it...\n",
    "\n",
    "Read in the college dataset, and find the mean and standard deviation of the undergraduate population by state:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>HBCU</th>\n",
       "      <th>MENONLY</th>\n",
       "      <th>WOMENONLY</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th>SATVRMID</th>\n",
       "      <th>SATMTMID</th>\n",
       "      <th>DISTANCEONLY</th>\n",
       "      <th>...</th>\n",
       "      <th>UGDS_2MOR</th>\n",
       "      <th>UGDS_NRA</th>\n",
       "      <th>UGDS_UNKN</th>\n",
       "      <th>PPTUG_EF</th>\n",
       "      <th>CURROPER</th>\n",
       "      <th>PCTPELL</th>\n",
       "      <th>PCTFLOAN</th>\n",
       "      <th>UG25ABV</th>\n",
       "      <th>MD_EARN_WNE_P10</th>\n",
       "      <th>GRAD_DEBT_MDN_SUPP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7356</td>\n",
       "      <td>0.8284</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>30300</td>\n",
       "      <td>33888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.2607</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>0.2422</td>\n",
       "      <td>39700</td>\n",
       "      <td>21941.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amridge University</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2715</td>\n",
       "      <td>0.4536</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>0.8540</td>\n",
       "      <td>40100</td>\n",
       "      <td>23370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University of Alabama in Huntsville</td>\n",
       "      <td>Huntsville</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.2146</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3072</td>\n",
       "      <td>0.4596</td>\n",
       "      <td>0.2640</td>\n",
       "      <td>45500</td>\n",
       "      <td>24097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama State University</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>AL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.0892</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7347</td>\n",
       "      <td>0.7554</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>26600</td>\n",
       "      <td>33118.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                INSTNM        CITY STABBR  HBCU  MENONLY  \\\n",
       "0             Alabama A & M University      Normal     AL   1.0      0.0   \n",
       "1  University of Alabama at Birmingham  Birmingham     AL   0.0      0.0   \n",
       "2                   Amridge University  Montgomery     AL   0.0      0.0   \n",
       "3  University of Alabama in Huntsville  Huntsville     AL   0.0      0.0   \n",
       "4             Alabama State University  Montgomery     AL   1.0      0.0   \n",
       "\n",
       "   WOMENONLY  RELAFFIL  SATVRMID  SATMTMID  DISTANCEONLY  ...  UGDS_2MOR  \\\n",
       "0        0.0         0     424.0     420.0           0.0  ...     0.0000   \n",
       "1        0.0         0     570.0     565.0           0.0  ...     0.0368   \n",
       "2        0.0         1       NaN       NaN           1.0  ...     0.0000   \n",
       "3        0.0         0     595.0     590.0           0.0  ...     0.0172   \n",
       "4        0.0         0     425.0     430.0           0.0  ...     0.0098   \n",
       "\n",
       "   UGDS_NRA  UGDS_UNKN  PPTUG_EF  CURROPER  PCTPELL  PCTFLOAN  UG25ABV  \\\n",
       "0    0.0059     0.0138    0.0656         1   0.7356    0.8284   0.1049   \n",
       "1    0.0179     0.0100    0.2607         1   0.3460    0.5214   0.2422   \n",
       "2    0.0000     0.2715    0.4536         1   0.6801    0.7795   0.8540   \n",
       "3    0.0332     0.0350    0.2146         1   0.3072    0.4596   0.2640   \n",
       "4    0.0243     0.0137    0.0892         1   0.7347    0.7554   0.1270   \n",
       "\n",
       "   MD_EARN_WNE_P10  GRAD_DEBT_MDN_SUPP  \n",
       "0            30300               33888  \n",
       "1            39700             21941.5  \n",
       "2            40100               23370  \n",
       "3            45500               24097  \n",
       "4            26600             33118.5  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college = pd.read_csv('data/college.csv')\n",
    "college.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABBR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>2493.0</td>\n",
       "      <td>4052.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>2790.0</td>\n",
       "      <td>4658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>1644.0</td>\n",
       "      <td>3143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AS</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>4130.0</td>\n",
       "      <td>14894.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean      std\n",
       "STABBR                 \n",
       "AK      2493.0   4052.0\n",
       "AL      2790.0   4658.0\n",
       "AR      1644.0   3143.0\n",
       "AS      1276.0      NaN\n",
       "AZ      4130.0  14894.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.groupby('STABBR')['UGDS'].agg(['mean', 'std']).round(0).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output isn't quite what we desire. We are not looking for the mean and standard deviations of the entire group but the maximum number of standard deviations away from the mean for any one institution. In order to calculate this, we need to subtract the mean undergraduate population by state from each institution's undergraduate population and then divide by the standard deviation. This standardizes the undergraduate population for each group. We can then take the maximum of the absolute value of these scores to find the one that is farthest away from the mean. Pandas does not provide a function capable of doing this. Instead, we will need to create a custom function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_deviation(s):\n",
    "    std_score = (s - s.mean()) / s.std()\n",
    "    return std_score.abs().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the function, pass it directly to the agg method to complete the aggregation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STABBR\n",
       "AK    2.6\n",
       "AL    5.8\n",
       "AR    6.3\n",
       "AS    NaN\n",
       "AZ    9.9\n",
       "Name: UGDS, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.groupby('STABBR')['UGDS'].agg(max_deviation).round(1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works...\n",
    "\n",
    "There does not exist a predefined pandas function to calculate the maximum number of standard deviations away from the mean. We were forced to construct a customized function in step 2. Notice that this custom function max_deviation accepts a single parameter, s. Looking ahead at step 3, you will notice that the function name is placed inside the agg method without directly being called. Nowhere is the parameter s explicitly passed to max_deviation. Instead, pandas implicitly passes the UGDS column as a Series to max_deviation.\n",
    "\n",
    "The max_deviation function is called once for each group. As s is a Series, all normal Series methods are available. It subtracts the mean of that particular grouping from each of the values in the group before dividing by the standard deviation in a process called standardization.\n",
    "\n",
    "**Note**\n",
    "\n",
    "Standardization is a common statistical procedure to understand how greatly individual values vary from the mean. For a normal distribution, 99.7% of the data lies within three standard deviations of the mean.\n",
    "\n",
    "As we are interested in absolute deviation from the mean, we take the absolute value from all the standardized scores and return the maximum. The agg method necessitates that a single scalar value must be returned from our custom function, or else an exception will be raised. Pandas defaults to using the sample standard deviation which is undefined for any groups with just a single value. For instance, the state abbreviation AS (American Samoa) has a missing value returned as it has only a single institution in the dataset.\n",
    "\n",
    "### There's more...\n",
    "\n",
    "It is possible to apply our customized function to multiple aggregating columns. We simply add more column names to the indexing operator. The max_deviation function only works with numeric columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UGDS</th>\n",
       "      <th>SATVRMID</th>\n",
       "      <th>SATMTMID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABBR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>2.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>9.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        UGDS  SATVRMID  SATMTMID\n",
       "STABBR                          \n",
       "AK       2.6       NaN       NaN\n",
       "AL       5.8       1.6       1.8\n",
       "AR       6.3       2.2       2.3\n",
       "AS       NaN       NaN       NaN\n",
       "AZ       9.9       1.9       1.4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.groupby('STABBR')[['UGDS', 'SATVRMID', 'SATMTMID']].agg(max_deviation).round(1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use your customized aggregation function along with the prebuilt functions. The following does this and groups by state and religious affiliation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">UGDS</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SATVRMID</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SATMTMID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>max_deviation</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max_deviation</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max_deviation</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABBR</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AK</th>\n",
       "      <th>0</th>\n",
       "      <td>2.1</td>\n",
       "      <td>3508.9</td>\n",
       "      <td>4539.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>123.3</td>\n",
       "      <td>132.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>555.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>503.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AL</th>\n",
       "      <th>0</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3248.8</td>\n",
       "      <td>5102.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>514.9</td>\n",
       "      <td>56.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>515.8</td>\n",
       "      <td>56.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.4</td>\n",
       "      <td>979.7</td>\n",
       "      <td>870.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>498.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>485.6</td>\n",
       "      <td>61.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <th>0</th>\n",
       "      <td>5.8</td>\n",
       "      <td>1793.7</td>\n",
       "      <td>3401.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>481.1</td>\n",
       "      <td>37.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>503.6</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         UGDS                      SATVRMID               \\\n",
       "                max_deviation    mean     std max_deviation   mean   std   \n",
       "STABBR RELAFFIL                                                            \n",
       "AK     0                  2.1  3508.9  4539.5           NaN    NaN   NaN   \n",
       "       1                  1.1   123.3   132.9           NaN  555.0   NaN   \n",
       "AL     0                  5.2  3248.8  5102.4           1.6  514.9  56.5   \n",
       "       1                  2.4   979.7   870.8           1.5  498.0  53.0   \n",
       "AR     0                  5.8  1793.7  3401.6           1.9  481.1  37.9   \n",
       "\n",
       "                     SATMTMID               \n",
       "                max_deviation   mean   std  \n",
       "STABBR RELAFFIL                             \n",
       "AK     0                  NaN    NaN   NaN  \n",
       "       1                  NaN  503.0   NaN  \n",
       "AL     0                  1.7  515.8  56.7  \n",
       "       1                  1.4  485.6  61.4  \n",
       "AR     0                  2.0  503.6  39.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.groupby(['STABBR', 'RELAFFIL'])[['UGDS', 'SATVRMID', 'SATMTMID']]\\\n",
    "       .agg([max_deviation, 'mean', 'std']).round(1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that pandas uses the name of the function as the name for the returned column. You can change the column name directly with the rename method or you can modify the special function attribute __name__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'max_deviation'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_deviation.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_deviation.__name__ = 'Max Deviation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">UGDS</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SATVRMID</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SATMTMID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Max Deviation</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>Max Deviation</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>Max Deviation</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABBR</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AK</th>\n",
       "      <th>0</th>\n",
       "      <td>2.1</td>\n",
       "      <td>3508.9</td>\n",
       "      <td>4539.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>123.3</td>\n",
       "      <td>132.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>555.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>503.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AL</th>\n",
       "      <th>0</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3248.8</td>\n",
       "      <td>5102.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>514.9</td>\n",
       "      <td>56.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>515.8</td>\n",
       "      <td>56.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.4</td>\n",
       "      <td>979.7</td>\n",
       "      <td>870.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>498.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>485.6</td>\n",
       "      <td>61.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <th>0</th>\n",
       "      <td>5.8</td>\n",
       "      <td>1793.7</td>\n",
       "      <td>3401.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>481.1</td>\n",
       "      <td>37.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>503.6</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         UGDS                      SATVRMID               \\\n",
       "                Max Deviation    mean     std Max Deviation   mean   std   \n",
       "STABBR RELAFFIL                                                            \n",
       "AK     0                  2.1  3508.9  4539.5           NaN    NaN   NaN   \n",
       "       1                  1.1   123.3   132.9           NaN  555.0   NaN   \n",
       "AL     0                  5.2  3248.8  5102.4           1.6  514.9  56.5   \n",
       "       1                  2.4   979.7   870.8           1.5  498.0  53.0   \n",
       "AR     0                  5.8  1793.7  3401.6           1.9  481.1  37.9   \n",
       "\n",
       "                     SATMTMID               \n",
       "                Max Deviation   mean   std  \n",
       "STABBR RELAFFIL                             \n",
       "AK     0                  NaN    NaN   NaN  \n",
       "       1                  NaN  503.0   NaN  \n",
       "AL     0                  1.7  515.8  56.7  \n",
       "       1                  1.4  485.6  61.4  \n",
       "AR     0                  2.0  503.6  39.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.groupby(['STABBR', 'RELAFFIL'])[['UGDS', 'SATVRMID', 'SATMTMID']]\\\n",
    "       .agg([max_deviation, 'mean', 'std']).round(1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing aggregating functions with kwargs and args\n",
    "When writing your own user-defined customized aggregation function, pandas implicitly passes it each of the aggregating columns one at a time as a Series. Occasionally, you will need to pass more arguments to your function than just the Series itself. To do so, you need to be aware of Python's ability to pass an arbitrary number of arguments to functions. Let's take a look at the signature of the groupby object's agg method with help from the inspect module:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "college = pd.read_csv('data/college.csv')\n",
    "grouped = college.groupby(['STABBR', 'RELAFFIL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (func=None, *args, engine=None, engine_kwargs=None, **kwargs)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "inspect.signature(grouped.agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument *args allow you to pass an arbitrary number of non-keyword arguments to your customized aggregation function. Similarly, **kwargs allows you to pass an arbitrary number of keyword arguments.\n",
    "\n",
    "### Getting ready\n",
    "\n",
    "In this recipe, we build a customized function for the college dataset that finds the percentage of schools by state and religious affiliation that have an undergraduate population between two values.\n",
    "\n",
    "### How to do it...\n",
    "\n",
    "Define a function that returns the percentage of schools with an undergraduate population between 1,000 and 3,000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_between_1_3k(s):\n",
    "    return s.between(1000, 3000).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate this percentage grouping by state and religious affiliation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STABBR  RELAFFIL\n",
       "AK      0           0.142857\n",
       "        1           0.000000\n",
       "AL      0           0.236111\n",
       "        1           0.333333\n",
       "AR      0           0.279412\n",
       "        1           0.111111\n",
       "AS      0           1.000000\n",
       "AZ      0           0.096774\n",
       "        1           0.000000\n",
       "Name: UGDS, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.groupby(['STABBR', 'RELAFFIL'])['UGDS'].agg(pct_between_1_3k).head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function works fine but it doesn't give the user any flexibility to choose the lower and upper bound. Let's create a new function that allows the user to define these bounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_between(s, low, high):\n",
    "    return s.between(low, high).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass this new function to the agg method along with lower and upper bounds:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STABBR  RELAFFIL\n",
       "AK      0           0.428571\n",
       "        1           0.000000\n",
       "AL      0           0.458333\n",
       "        1           0.375000\n",
       "AR      0           0.397059\n",
       "        1           0.166667\n",
       "AS      0           1.000000\n",
       "AZ      0           0.233871\n",
       "        1           0.111111\n",
       "Name: UGDS, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.groupby(['STABBR', 'RELAFFIL'])['UGDS'].agg(pct_between, 1000, 10000).head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works...\n",
    "\n",
    "Step 1 creates a function that doesn't accept any extra arguments. The upper and lower bounds must be hardcoded into the function itself, which isn't very flexible. Step 2 shows the results of this aggregation.\n",
    "\n",
    "We create a more flexible function in step 3 that allows users to define both the lower and upper bounds dynamically. Step 4 is where the magic of *args and **kwargs come into play. In this particular example, we pass two non-keyword arguments, 1,000 and 10,000, to the agg method. Pandas passes these two arguments respectively to the low and high parameters of pct_between.\n",
    "\n",
    "There are a few ways we could achieve the same result in step 4. We could have explicitly used the parameter names with the following command to produce the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STABBR  RELAFFIL\n",
       "AK      0           0.428571\n",
       "        1           0.000000\n",
       "AL      0           0.458333\n",
       "        1           0.375000\n",
       "AR      0           0.397059\n",
       "        1           0.166667\n",
       "AS      0           1.000000\n",
       "AZ      0           0.233871\n",
       "        1           0.111111\n",
       "Name: UGDS, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.groupby(['STABBR', 'RELAFFIL'])['UGDS'].agg(pct_between, high=10000, low=1000).head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order of the keyword arguments doesn't matter as long as they come after the function name. Further still, we can mix non-keyword and keyword arguments as long as the keyword arguments come last:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STABBR  RELAFFIL\n",
       "AK      0           0.428571\n",
       "        1           0.000000\n",
       "AL      0           0.458333\n",
       "        1           0.375000\n",
       "AR      0           0.397059\n",
       "        1           0.166667\n",
       "AS      0           1.000000\n",
       "AZ      0           0.233871\n",
       "        1           0.111111\n",
       "Name: UGDS, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.groupby(['STABBR', 'RELAFFIL'])['UGDS'].agg(pct_between, 1000, high=10000).head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of understanding, it's probably best to include all the parameter names in the order that they are defined in the function signature.\n",
    "\n",
    "**Note**\n",
    "\n",
    "Technically, when agg is called, all the non-keyword arguments get collected into a tuple named args and all the keyword arguments get collected into a dictionary named kwargs.\n",
    "\n",
    "### There's more...\n",
    "\n",
    "Unfortunately, pandas does not have a direct way to use these additional arguments when using multiple aggregation functions together. For example, if you wish to aggregate using the pct_between and mean functions, you will get the following exception:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GroupBy.mean() got an unexpected keyword argument 'low'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcollege\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSTABBR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRELAFFIL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUGDS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpct_between\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhigh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:255\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine\n\u001b[0;32m    254\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[1;32m--> 255\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_multiple_funcs(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;66;03m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:360\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_multiple_funcs\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, func) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arg):\n\u001b[0;32m    359\u001b[0m         key \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mOutputKey(label\u001b[38;5;241m=\u001b[39mname, position\u001b[38;5;241m=\u001b[39midx)\n\u001b[1;32m--> 360\u001b[0m         results[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, DataFrame) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:247\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    246\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, func)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, abc\u001b[38;5;241m.\u001b[39mIterable):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# Catch instances of lists / tuples\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;66;03m# but not the class list / tuple itself.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     func \u001b[38;5;241m=\u001b[39m maybe_mangle_lambdas(func)\n",
      "\u001b[1;31mTypeError\u001b[0m: GroupBy.mean() got an unexpected keyword argument 'low'"
     ]
    }
   ],
   "source": [
    "college.groupby(['STABBR', 'RELAFFIL'])['UGDS'].agg(['mean', pct_between], low=100, high=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is incapable of understanding that the extra arguments need to be passed to pct_between. In order to use our custom function with other built-in functions and even other custom functions, we can define a special type of nested function called a closure. We can use a generic closure to build all of our customized functions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_agg_func(func, name, *args, **kwargs):\n",
    "    def wrapper(x):\n",
    "        return func(x, *args, **kwargs)\n",
    "    wrapper.__name__ = name\n",
    "    return wrapper\n",
    "\n",
    "my_agg1 = make_agg_func(pct_between, 'pct_1_3k', low=1000, high=3000)\n",
    "my_agg2 = make_agg_func(pct_between, 'pct_10_30k', 10000, 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>pct_1_3k</th>\n",
       "      <th>pct_10_30k</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABBR</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AK</th>\n",
       "      <th>0</th>\n",
       "      <td>3508.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AL</th>\n",
       "      <th>0</th>\n",
       "      <td>3248.774648</td>\n",
       "      <td>0.236111</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>979.722222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <th>0</th>\n",
       "      <td>1793.691176</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.014706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean  pct_1_3k  pct_10_30k\n",
       "STABBR RELAFFIL                                   \n",
       "AK     0         3508.857143  0.142857    0.142857\n",
       "       1          123.333333  0.000000    0.000000\n",
       "AL     0         3248.774648  0.236111    0.083333\n",
       "       1          979.722222  0.333333    0.000000\n",
       "AR     0         1793.691176  0.279412    0.014706"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.groupby(['STABBR', 'RELAFFIL'])['UGDS'].agg(['mean', my_agg1, my_agg2]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The make_agg_func function acts as a factory to create customized aggregation functions. It accepts the customized aggregation function that you already built (pct_between in this case), a name argument, and an arbitrary number of extra arguments. It returns a function with the extra arguments already set. For instance, my_agg1 is a specific customized aggregating function that finds the percentage of schools with an undergraduate population between one and three thousand. The extra arguments (*args and **kwargs) specify an exact set of parameters for your customized function (pct_between in this case). The name parameter is very important and must be unique each time make_agg_func is called. It will eventually be used to rename the aggregated column.\n",
    "\n",
    "**Note**\n",
    "\n",
    "A closure is a function that contains a function inside of it (a nested function) and returns this nested function. This nested function must refer to variables in the scope of the outer function in order to be a closure. In this example, make_agg_func is the outer function and returns the nested function wrapper, which accesses the variables func, args, and kwargs from the outer function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining a groupby object\n",
    "The immediate result from using the groupby method on a DataFrame will be a groupby object. Usually, we continue operating on this object to do aggregations or transformations without ever saving it to a variable. One of the primary purposes of examining this groupby object is to inspect individual groups.\n",
    "\n",
    "### Getting ready\n",
    "\n",
    "In this recipe, we examine the groupby object itself by directly calling methods on it as well as iterating through each of its groups.\n",
    "\n",
    "### How to do it...\n",
    "\n",
    "Let's get started by grouping the state and religious affiliation columns from the college dataset, saving the result to a variable and confirming its type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.groupby.generic.DataFrameGroupBy"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college = pd.read_csv('data/college.csv')\n",
    "grouped = college.groupby(['STABBR', 'RELAFFIL'])\n",
    "type(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the dir function to discover all its available functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CITY', 'CURROPER', 'DISTANCEONLY', 'GRAD_DEBT_MDN_SUPP', 'HBCU', 'INSTNM', 'MD_EARN_WNE_P10', 'MENONLY', 'PCTFLOAN', 'PCTPELL', 'PPTUG_EF', 'RELAFFIL', 'SATMTMID', 'SATVRMID', 'STABBR', 'UG25ABV', 'UGDS', 'UGDS_2MOR', 'UGDS_AIAN', 'UGDS_ASIAN', 'UGDS_BLACK', 'UGDS_HISP', 'UGDS_NHPI', 'UGDS_NRA', 'UGDS_UNKN', 'UGDS_WHITE', 'WOMENONLY', 'agg', 'aggregate', 'all', 'any', 'apply', 'bfill', 'boxplot', 'corr', 'corrwith', 'count', 'cov', 'cumcount', 'cummax', 'cummin', 'cumprod', 'cumsum', 'describe', 'diff', 'dtypes', 'ewm', 'expanding', 'ffill', 'fillna', 'filter', 'first', 'get_group', 'groups', 'head', 'hist', 'idxmax', 'idxmin', 'indices', 'last', 'max', 'mean', 'median', 'min', 'ndim', 'ngroup', 'ngroups', 'nth', 'nunique', 'ohlc', 'pct_change', 'pipe', 'plot', 'prod', 'quantile', 'rank', 'resample', 'rolling', 'sample', 'sem', 'shift', 'size', 'skew', 'std', 'sum', 'tail', 'take', 'transform', 'value_counts', 'var']\n"
     ]
    }
   ],
   "source": [
    "print([attr for attr in dir(grouped) if not attr.startswith('_')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the number of groups with the ngroups attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.ngroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the uniquely identifying labels for each group, look in the groups attribute, which contains a dictionary of each unique group mapped to all the corresponding index labels of that group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AK', 0), ('AK', 1), ('AL', 0), ('AL', 1), ('AR', 0), ('AR', 1)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = list(grouped.groups.keys())\n",
    "groups[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a single group with the get_group method by passing it a tuple of an exact group label. For example, to get all the religiously affiliated schools in the state of Florida, do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>HBCU</th>\n",
       "      <th>MENONLY</th>\n",
       "      <th>WOMENONLY</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th>SATVRMID</th>\n",
       "      <th>SATMTMID</th>\n",
       "      <th>DISTANCEONLY</th>\n",
       "      <th>...</th>\n",
       "      <th>UGDS_2MOR</th>\n",
       "      <th>UGDS_NRA</th>\n",
       "      <th>UGDS_UNKN</th>\n",
       "      <th>PPTUG_EF</th>\n",
       "      <th>CURROPER</th>\n",
       "      <th>PCTPELL</th>\n",
       "      <th>PCTFLOAN</th>\n",
       "      <th>UG25ABV</th>\n",
       "      <th>MD_EARN_WNE_P10</th>\n",
       "      <th>GRAD_DEBT_MDN_SUPP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>The Baptist College of Florida</td>\n",
       "      <td>Graceville</td>\n",
       "      <td>FL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>545.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0507</td>\n",
       "      <td>0.2291</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5878</td>\n",
       "      <td>0.5602</td>\n",
       "      <td>0.3531</td>\n",
       "      <td>30800</td>\n",
       "      <td>20052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>Barry University</td>\n",
       "      <td>Miami</td>\n",
       "      <td>FL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>470.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>0.1518</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5045</td>\n",
       "      <td>0.6733</td>\n",
       "      <td>0.4361</td>\n",
       "      <td>44100</td>\n",
       "      <td>28250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>Gooding Institute of Nurse Anesthesia</td>\n",
       "      <td>Panama City</td>\n",
       "      <td>FL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>Bethune-Cookman University</td>\n",
       "      <td>Daytona Beach</td>\n",
       "      <td>FL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>405.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7758</td>\n",
       "      <td>0.8867</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>29400</td>\n",
       "      <td>36250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>Johnson University Florida</td>\n",
       "      <td>Kissimmee</td>\n",
       "      <td>FL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>480.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.1636</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6689</td>\n",
       "      <td>0.7384</td>\n",
       "      <td>0.2185</td>\n",
       "      <td>26300</td>\n",
       "      <td>20199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    INSTNM           CITY STABBR  HBCU  \\\n",
       "712         The Baptist College of Florida     Graceville     FL   0.0   \n",
       "713                       Barry University          Miami     FL   0.0   \n",
       "714  Gooding Institute of Nurse Anesthesia    Panama City     FL   0.0   \n",
       "715             Bethune-Cookman University  Daytona Beach     FL   1.0   \n",
       "724             Johnson University Florida      Kissimmee     FL   0.0   \n",
       "\n",
       "     MENONLY  WOMENONLY  RELAFFIL  SATVRMID  SATMTMID  DISTANCEONLY  ...  \\\n",
       "712      0.0        0.0         1     545.0     465.0           0.0  ...   \n",
       "713      0.0        0.0         1     470.0     462.0           0.0  ...   \n",
       "714      0.0        0.0         1       NaN       NaN           0.0  ...   \n",
       "715      0.0        0.0         1     405.0     395.0           0.0  ...   \n",
       "724      0.0        0.0         1     480.0     470.0           0.0  ...   \n",
       "\n",
       "     UGDS_2MOR  UGDS_NRA  UGDS_UNKN  PPTUG_EF  CURROPER  PCTPELL  PCTFLOAN  \\\n",
       "712     0.0308    0.0000     0.0507    0.2291         1   0.5878    0.5602   \n",
       "713     0.0164    0.0741     0.0841    0.1518         1   0.5045    0.6733   \n",
       "714        NaN       NaN        NaN       NaN         0      NaN       NaN   \n",
       "715     0.0198    0.0205     0.0190    0.0523         1   0.7758    0.8867   \n",
       "724     0.0045    0.0045     0.0136    0.1636         1   0.6689    0.7384   \n",
       "\n",
       "     UG25ABV  MD_EARN_WNE_P10  GRAD_DEBT_MDN_SUPP  \n",
       "712   0.3531            30800               20052  \n",
       "713   0.4361            44100               28250  \n",
       "714      NaN              NaN   PrivacySuppressed  \n",
       "715   0.0647            29400               36250  \n",
       "724   0.2185            26300               20199  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.get_group(('FL', 1)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to take a peek at each individual group. This is possible because groupby objects are iterable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AK', 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>HBCU</th>\n",
       "      <th>MENONLY</th>\n",
       "      <th>WOMENONLY</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th>SATVRMID</th>\n",
       "      <th>SATMTMID</th>\n",
       "      <th>DISTANCEONLY</th>\n",
       "      <th>...</th>\n",
       "      <th>UGDS_2MOR</th>\n",
       "      <th>UGDS_NRA</th>\n",
       "      <th>UGDS_UNKN</th>\n",
       "      <th>PPTUG_EF</th>\n",
       "      <th>CURROPER</th>\n",
       "      <th>PCTPELL</th>\n",
       "      <th>PCTFLOAN</th>\n",
       "      <th>UG25ABV</th>\n",
       "      <th>MD_EARN_WNE_P10</th>\n",
       "      <th>GRAD_DEBT_MDN_SUPP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>University of Alaska Anchorage</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0457</td>\n",
       "      <td>0.4539</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2385</td>\n",
       "      <td>0.2647</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>42500</td>\n",
       "      <td>19449.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>University of Alaska Fairbanks</td>\n",
       "      <td>Fairbanks</td>\n",
       "      <td>AK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.3060</td>\n",
       "      <td>0.3887</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.2550</td>\n",
       "      <td>0.4519</td>\n",
       "      <td>36200</td>\n",
       "      <td>19355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            INSTNM       CITY STABBR  HBCU  MENONLY  \\\n",
       "60  University of Alaska Anchorage  Anchorage     AK   0.0      0.0   \n",
       "62  University of Alaska Fairbanks  Fairbanks     AK   0.0      0.0   \n",
       "\n",
       "    WOMENONLY  RELAFFIL  SATVRMID  SATMTMID  DISTANCEONLY  ...  UGDS_2MOR  \\\n",
       "60        0.0         0       NaN       NaN           0.0  ...     0.0980   \n",
       "62        0.0         0       NaN       NaN           0.0  ...     0.0401   \n",
       "\n",
       "    UGDS_NRA  UGDS_UNKN  PPTUG_EF  CURROPER  PCTPELL  PCTFLOAN  UG25ABV  \\\n",
       "60    0.0181     0.0457    0.4539         1   0.2385    0.2647   0.4386   \n",
       "62    0.0110     0.3060    0.3887         1   0.2263    0.2550   0.4519   \n",
       "\n",
       "    MD_EARN_WNE_P10  GRAD_DEBT_MDN_SUPP  \n",
       "60            42500             19449.5  \n",
       "62            36200               19355  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AK', 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>HBCU</th>\n",
       "      <th>MENONLY</th>\n",
       "      <th>WOMENONLY</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th>SATVRMID</th>\n",
       "      <th>SATMTMID</th>\n",
       "      <th>DISTANCEONLY</th>\n",
       "      <th>...</th>\n",
       "      <th>UGDS_2MOR</th>\n",
       "      <th>UGDS_NRA</th>\n",
       "      <th>UGDS_UNKN</th>\n",
       "      <th>PPTUG_EF</th>\n",
       "      <th>CURROPER</th>\n",
       "      <th>PCTPELL</th>\n",
       "      <th>PCTFLOAN</th>\n",
       "      <th>UG25ABV</th>\n",
       "      <th>MD_EARN_WNE_P10</th>\n",
       "      <th>GRAD_DEBT_MDN_SUPP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Alaska Bible College</td>\n",
       "      <td>Palmer</td>\n",
       "      <td>AK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1481</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Alaska Pacific University</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>555.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0873</td>\n",
       "      <td>0.3745</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3152</td>\n",
       "      <td>0.5297</td>\n",
       "      <td>0.4910</td>\n",
       "      <td>47000</td>\n",
       "      <td>23250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       INSTNM       CITY STABBR  HBCU  MENONLY  WOMENONLY  \\\n",
       "61       Alaska Bible College     Palmer     AK   0.0      0.0        0.0   \n",
       "64  Alaska Pacific University  Anchorage     AK   0.0      0.0        0.0   \n",
       "\n",
       "    RELAFFIL  SATVRMID  SATMTMID  DISTANCEONLY  ...  UGDS_2MOR  UGDS_NRA  \\\n",
       "61         1       NaN       NaN           0.0  ...     0.0370       0.0   \n",
       "64         1     555.0     503.0           0.0  ...     0.0945       0.0   \n",
       "\n",
       "    UGDS_UNKN  PPTUG_EF  CURROPER  PCTPELL  PCTFLOAN  UG25ABV  \\\n",
       "61     0.0000    0.1481         1   0.3571    0.2857   0.4286   \n",
       "64     0.0873    0.3745         1   0.3152    0.5297   0.4910   \n",
       "\n",
       "    MD_EARN_WNE_P10  GRAD_DEBT_MDN_SUPP  \n",
       "61              NaN   PrivacySuppressed  \n",
       "64            47000               23250  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AL', 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>HBCU</th>\n",
       "      <th>MENONLY</th>\n",
       "      <th>WOMENONLY</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th>SATVRMID</th>\n",
       "      <th>SATMTMID</th>\n",
       "      <th>DISTANCEONLY</th>\n",
       "      <th>...</th>\n",
       "      <th>UGDS_2MOR</th>\n",
       "      <th>UGDS_NRA</th>\n",
       "      <th>UGDS_UNKN</th>\n",
       "      <th>PPTUG_EF</th>\n",
       "      <th>CURROPER</th>\n",
       "      <th>PCTPELL</th>\n",
       "      <th>PCTFLOAN</th>\n",
       "      <th>UG25ABV</th>\n",
       "      <th>MD_EARN_WNE_P10</th>\n",
       "      <th>GRAD_DEBT_MDN_SUPP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7356</td>\n",
       "      <td>0.8284</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>30300</td>\n",
       "      <td>33888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.2607</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>0.2422</td>\n",
       "      <td>39700</td>\n",
       "      <td>21941.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                INSTNM        CITY STABBR  HBCU  MENONLY  \\\n",
       "0             Alabama A & M University      Normal     AL   1.0      0.0   \n",
       "1  University of Alabama at Birmingham  Birmingham     AL   0.0      0.0   \n",
       "\n",
       "   WOMENONLY  RELAFFIL  SATVRMID  SATMTMID  DISTANCEONLY  ...  UGDS_2MOR  \\\n",
       "0        0.0         0     424.0     420.0           0.0  ...     0.0000   \n",
       "1        0.0         0     570.0     565.0           0.0  ...     0.0368   \n",
       "\n",
       "   UGDS_NRA  UGDS_UNKN  PPTUG_EF  CURROPER  PCTPELL  PCTFLOAN  UG25ABV  \\\n",
       "0    0.0059     0.0138    0.0656         1   0.7356    0.8284   0.1049   \n",
       "1    0.0179     0.0100    0.2607         1   0.3460    0.5214   0.2422   \n",
       "\n",
       "   MD_EARN_WNE_P10  GRAD_DEBT_MDN_SUPP  \n",
       "0            30300               33888  \n",
       "1            39700             21941.5  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AL', 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>HBCU</th>\n",
       "      <th>MENONLY</th>\n",
       "      <th>WOMENONLY</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th>SATVRMID</th>\n",
       "      <th>SATMTMID</th>\n",
       "      <th>DISTANCEONLY</th>\n",
       "      <th>...</th>\n",
       "      <th>UGDS_2MOR</th>\n",
       "      <th>UGDS_NRA</th>\n",
       "      <th>UGDS_UNKN</th>\n",
       "      <th>PPTUG_EF</th>\n",
       "      <th>CURROPER</th>\n",
       "      <th>PCTPELL</th>\n",
       "      <th>PCTFLOAN</th>\n",
       "      <th>UG25ABV</th>\n",
       "      <th>MD_EARN_WNE_P10</th>\n",
       "      <th>GRAD_DEBT_MDN_SUPP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amridge University</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2715</td>\n",
       "      <td>0.4536</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>0.8540</td>\n",
       "      <td>40100</td>\n",
       "      <td>23370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Birmingham Southern College</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>560.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.4809</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>44200</td>\n",
       "      <td>27000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         INSTNM        CITY STABBR  HBCU  MENONLY  WOMENONLY  \\\n",
       "2            Amridge University  Montgomery     AL   0.0      0.0        0.0   \n",
       "10  Birmingham Southern College  Birmingham     AL   0.0      0.0        0.0   \n",
       "\n",
       "    RELAFFIL  SATVRMID  SATMTMID  DISTANCEONLY  ...  UGDS_2MOR  UGDS_NRA  \\\n",
       "2          1       NaN       NaN           1.0  ...     0.0000       0.0   \n",
       "10         1     560.0     560.0           0.0  ...     0.0051       0.0   \n",
       "\n",
       "    UGDS_UNKN  PPTUG_EF  CURROPER  PCTPELL  PCTFLOAN  UG25ABV  \\\n",
       "2      0.2715    0.4536         1   0.6801    0.7795   0.8540   \n",
       "10     0.0051    0.0017         1   0.1920    0.4809   0.0152   \n",
       "\n",
       "    MD_EARN_WNE_P10  GRAD_DEBT_MDN_SUPP  \n",
       "2             40100               23370  \n",
       "10            44200               27000  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AR', 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>HBCU</th>\n",
       "      <th>MENONLY</th>\n",
       "      <th>WOMENONLY</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th>SATVRMID</th>\n",
       "      <th>SATMTMID</th>\n",
       "      <th>DISTANCEONLY</th>\n",
       "      <th>...</th>\n",
       "      <th>UGDS_2MOR</th>\n",
       "      <th>UGDS_NRA</th>\n",
       "      <th>UGDS_UNKN</th>\n",
       "      <th>PPTUG_EF</th>\n",
       "      <th>CURROPER</th>\n",
       "      <th>PCTPELL</th>\n",
       "      <th>PCTFLOAN</th>\n",
       "      <th>UG25ABV</th>\n",
       "      <th>MD_EARN_WNE_P10</th>\n",
       "      <th>GRAD_DEBT_MDN_SUPP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>University of Arkansas at Little Rock</td>\n",
       "      <td>Little Rock</td>\n",
       "      <td>AR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.4126</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3941</td>\n",
       "      <td>0.4775</td>\n",
       "      <td>0.4062</td>\n",
       "      <td>33900</td>\n",
       "      <td>21736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>University of Arkansas for Medical Sciences</td>\n",
       "      <td>Little Rock</td>\n",
       "      <td>AR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0281</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.2433</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3944</td>\n",
       "      <td>0.6144</td>\n",
       "      <td>0.5133</td>\n",
       "      <td>61400</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          INSTNM         CITY STABBR  HBCU  \\\n",
       "128        University of Arkansas at Little Rock  Little Rock     AR   0.0   \n",
       "129  University of Arkansas for Medical Sciences  Little Rock     AR   0.0   \n",
       "\n",
       "     MENONLY  WOMENONLY  RELAFFIL  SATVRMID  SATMTMID  DISTANCEONLY  ...  \\\n",
       "128      0.0        0.0         0     470.0     510.0           0.0  ...   \n",
       "129      0.0        0.0         0       NaN       NaN           0.0  ...   \n",
       "\n",
       "     UGDS_2MOR  UGDS_NRA  UGDS_UNKN  PPTUG_EF  CURROPER  PCTPELL  PCTFLOAN  \\\n",
       "128     0.0755    0.0283     0.0003    0.4126         1   0.3941    0.4775   \n",
       "129     0.0281    0.0070     0.0169    0.2433         1   0.3944    0.6144   \n",
       "\n",
       "     UG25ABV  MD_EARN_WNE_P10  GRAD_DEBT_MDN_SUPP  \n",
       "128   0.4062            33900               21736  \n",
       "129   0.5133            61400               12500  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "for name, group in grouped:\n",
    "    print(name)\n",
    "    display(group.head(2))\n",
    "    i += 1\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also call the head method on your groupby object to get the first rows of each group together in a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>HBCU</th>\n",
       "      <th>MENONLY</th>\n",
       "      <th>WOMENONLY</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th>SATVRMID</th>\n",
       "      <th>SATMTMID</th>\n",
       "      <th>DISTANCEONLY</th>\n",
       "      <th>...</th>\n",
       "      <th>UGDS_2MOR</th>\n",
       "      <th>UGDS_NRA</th>\n",
       "      <th>UGDS_UNKN</th>\n",
       "      <th>PPTUG_EF</th>\n",
       "      <th>CURROPER</th>\n",
       "      <th>PCTPELL</th>\n",
       "      <th>PCTFLOAN</th>\n",
       "      <th>UG25ABV</th>\n",
       "      <th>MD_EARN_WNE_P10</th>\n",
       "      <th>GRAD_DEBT_MDN_SUPP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7356</td>\n",
       "      <td>0.8284</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>30300</td>\n",
       "      <td>33888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.2607</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>0.2422</td>\n",
       "      <td>39700</td>\n",
       "      <td>21941.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amridge University</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2715</td>\n",
       "      <td>0.4536</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>0.8540</td>\n",
       "      <td>40100</td>\n",
       "      <td>23370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Birmingham Southern College</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>560.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.4809</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>44200</td>\n",
       "      <td>27000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Prince Institute-Southeast</td>\n",
       "      <td>Elmhurst</td>\n",
       "      <td>IL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7857</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.6569</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>20992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>University of Alaska Anchorage</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0457</td>\n",
       "      <td>0.4539</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2385</td>\n",
       "      <td>0.2647</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>42500</td>\n",
       "      <td>19449.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 INSTNM        CITY STABBR  HBCU  MENONLY  \\\n",
       "0              Alabama A & M University      Normal     AL   1.0      0.0   \n",
       "1   University of Alabama at Birmingham  Birmingham     AL   0.0      0.0   \n",
       "2                    Amridge University  Montgomery     AL   0.0      0.0   \n",
       "10          Birmingham Southern College  Birmingham     AL   0.0      0.0   \n",
       "43           Prince Institute-Southeast    Elmhurst     IL   0.0      0.0   \n",
       "60       University of Alaska Anchorage   Anchorage     AK   0.0      0.0   \n",
       "\n",
       "    WOMENONLY  RELAFFIL  SATVRMID  SATMTMID  DISTANCEONLY  ...  UGDS_2MOR  \\\n",
       "0         0.0         0     424.0     420.0           0.0  ...     0.0000   \n",
       "1         0.0         0     570.0     565.0           0.0  ...     0.0368   \n",
       "2         0.0         1       NaN       NaN           1.0  ...     0.0000   \n",
       "10        0.0         1     560.0     560.0           0.0  ...     0.0051   \n",
       "43        0.0         0       NaN       NaN           0.0  ...     0.0000   \n",
       "60        0.0         0       NaN       NaN           0.0  ...     0.0980   \n",
       "\n",
       "    UGDS_NRA  UGDS_UNKN  PPTUG_EF  CURROPER  PCTPELL  PCTFLOAN  UG25ABV  \\\n",
       "0     0.0059     0.0138    0.0656         1   0.7356    0.8284   0.1049   \n",
       "1     0.0179     0.0100    0.2607         1   0.3460    0.5214   0.2422   \n",
       "2     0.0000     0.2715    0.4536         1   0.6801    0.7795   0.8540   \n",
       "10    0.0000     0.0051    0.0017         1   0.1920    0.4809   0.0152   \n",
       "43    0.0000     0.0000    0.0000         1   0.7857    0.9375   0.6569   \n",
       "60    0.0181     0.0457    0.4539         1   0.2385    0.2647   0.4386   \n",
       "\n",
       "      MD_EARN_WNE_P10  GRAD_DEBT_MDN_SUPP  \n",
       "0               30300               33888  \n",
       "1               39700             21941.5  \n",
       "2               40100               23370  \n",
       "10              44200               27000  \n",
       "43  PrivacySuppressed               20992  \n",
       "60              42500             19449.5  \n",
       "\n",
       "[6 rows x 27 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.head(2).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works...\n",
    "\n",
    "Step 1 formally creates our groupby object. It is useful to display all the public attributes and methods to reveal all the possible functionality as was done in step 2. Each group is uniquely identified by a tuple containing a unique combination of the values in the grouping columns. Pandas allows you to select a specific group as a DataFrame with the get_group method shown in step 5.\n",
    "\n",
    "It is rare that you will need to iterate through your groups and in general, you should avoid doing so if necessary, as it can be quite slow. Occasionally, you will have no other choice. When iterating through a groupby object, you are given a tuple containing the group name and the DataFrame without the grouping columns. This tuple is unpacked into the variables name and group in the for-loop in step 6.\n",
    "\n",
    "One interesting thing you can do while iterating through your groups is to display a few of the rows from each group directly in the notebook. To do this, you can either use the print function or the display function from the IPython.display module. Using the print function results in DataFrames that are in plain text without any nice HTML formatting. Using the display function will produce DataFrames in their normal easy-to-read format. \n",
    "\n",
    "### There's more...\n",
    "\n",
    "There are several useful methods that were not explored from the list in step 2. Take for instance the nth method, which, when given a list of integers, selects those specific rows from each group. For example, the following operation selects the first and last rows from each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>HBCU</th>\n",
       "      <th>MENONLY</th>\n",
       "      <th>WOMENONLY</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th>SATVRMID</th>\n",
       "      <th>SATMTMID</th>\n",
       "      <th>DISTANCEONLY</th>\n",
       "      <th>...</th>\n",
       "      <th>UGDS_2MOR</th>\n",
       "      <th>UGDS_NRA</th>\n",
       "      <th>UGDS_UNKN</th>\n",
       "      <th>PPTUG_EF</th>\n",
       "      <th>CURROPER</th>\n",
       "      <th>PCTPELL</th>\n",
       "      <th>PCTFLOAN</th>\n",
       "      <th>UG25ABV</th>\n",
       "      <th>MD_EARN_WNE_P10</th>\n",
       "      <th>GRAD_DEBT_MDN_SUPP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.2607</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>0.2422</td>\n",
       "      <td>39700</td>\n",
       "      <td>21941.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Birmingham Southern College</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>560.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.4809</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>44200</td>\n",
       "      <td>27000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>University of Alaska Fairbanks</td>\n",
       "      <td>Fairbanks</td>\n",
       "      <td>AK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.3060</td>\n",
       "      <td>0.3887</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.2550</td>\n",
       "      <td>0.4519</td>\n",
       "      <td>36200</td>\n",
       "      <td>19355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Alaska Pacific University</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>555.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0873</td>\n",
       "      <td>0.3745</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3152</td>\n",
       "      <td>0.5297</td>\n",
       "      <td>0.4910</td>\n",
       "      <td>47000</td>\n",
       "      <td>23250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Empire Beauty School-Paradise Valley</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6349</td>\n",
       "      <td>0.5873</td>\n",
       "      <td>0.4651</td>\n",
       "      <td>17800</td>\n",
       "      <td>9588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Empire Beauty School-Tucson</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7962</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>0.4229</td>\n",
       "      <td>18200</td>\n",
       "      <td>9833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>University of Arkansas for Medical Sciences</td>\n",
       "      <td>Little Rock</td>\n",
       "      <td>AR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0281</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.2433</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3944</td>\n",
       "      <td>0.6144</td>\n",
       "      <td>0.5133</td>\n",
       "      <td>61400</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Lyon College</td>\n",
       "      <td>Batesville</td>\n",
       "      <td>AR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>505.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0638</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4578</td>\n",
       "      <td>0.6740</td>\n",
       "      <td>0.0524</td>\n",
       "      <td>38600</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          INSTNM         CITY STABBR  HBCU  \\\n",
       "1            University of Alabama at Birmingham   Birmingham     AL   0.0   \n",
       "10                   Birmingham Southern College   Birmingham     AL   0.0   \n",
       "62                University of Alaska Fairbanks    Fairbanks     AK   0.0   \n",
       "64                     Alaska Pacific University    Anchorage     AK   0.0   \n",
       "70          Empire Beauty School-Paradise Valley      Phoenix     AZ   0.0   \n",
       "71                   Empire Beauty School-Tucson       Tucson     AZ   0.0   \n",
       "129  University of Arkansas for Medical Sciences  Little Rock     AR   0.0   \n",
       "134                                 Lyon College   Batesville     AR   0.0   \n",
       "\n",
       "     MENONLY  WOMENONLY  RELAFFIL  SATVRMID  SATMTMID  DISTANCEONLY  ...  \\\n",
       "1        0.0        0.0         0     570.0     565.0           0.0  ...   \n",
       "10       0.0        0.0         1     560.0     560.0           0.0  ...   \n",
       "62       0.0        0.0         0       NaN       NaN           0.0  ...   \n",
       "64       0.0        0.0         1     555.0     503.0           0.0  ...   \n",
       "70       0.0        0.0         1       NaN       NaN           0.0  ...   \n",
       "71       0.0        0.0         0       NaN       NaN           0.0  ...   \n",
       "129      0.0        0.0         0       NaN       NaN           0.0  ...   \n",
       "134      0.0        0.0         1     505.0     528.0           0.0  ...   \n",
       "\n",
       "     UGDS_2MOR  UGDS_NRA  UGDS_UNKN  PPTUG_EF  CURROPER  PCTPELL  PCTFLOAN  \\\n",
       "1       0.0368    0.0179     0.0100    0.2607         1   0.3460    0.5214   \n",
       "10      0.0051    0.0000     0.0051    0.0017         1   0.1920    0.4809   \n",
       "62      0.0401    0.0110     0.3060    0.3887         1   0.2263    0.2550   \n",
       "64      0.0945    0.0000     0.0873    0.3745         1   0.3152    0.5297   \n",
       "70      0.0400    0.0000     0.0000    0.1600         0   0.6349    0.5873   \n",
       "71      0.0000    0.0000     0.0079    0.2222         1   0.7962    0.6615   \n",
       "129     0.0281    0.0070     0.0169    0.2433         1   0.3944    0.6144   \n",
       "134     0.0000    0.0333     0.0638    0.0101         1   0.4578    0.6740   \n",
       "\n",
       "     UG25ABV  MD_EARN_WNE_P10  GRAD_DEBT_MDN_SUPP  \n",
       "1     0.2422            39700             21941.5  \n",
       "10    0.0152            44200               27000  \n",
       "62    0.4519            36200               19355  \n",
       "64    0.4910            47000               23250  \n",
       "70    0.4651            17800                9588  \n",
       "71    0.4229            18200                9833  \n",
       "129   0.5133            61400               12500  \n",
       "134   0.0524            38600               25000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.nth([1, -1]).head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering for states with minimum\n",
    "In Chapter 4, Selecting Subsets of Data, we marked every row as True or False before filtering out the False rows. In a similar fashion, it is possible to mark entire groups of data as either True or False before filtering out the False groups. To do this, we first form groups with the groupby method and then apply the filter method. The filter method accepts a function that must return either True or False to indicate whether a group is kept or not.\n",
    "\n",
    "**Note**\n",
    "\n",
    "This filter method applied after a call to the groupby method is completely different than the DataFrame filter method covered in the Selecting columns with methods recipe from Chapter 2, Essential DataFrame Operations.\n",
    "\n",
    "### Getting ready\n",
    "\n",
    "In this recipe, we use the college dataset to find all the states that have more non-white undergraduate students than white. As this is a dataset from the US, whites form the majority and therefore, we are looking for states with a minority majority.\n",
    "\n",
    "### How to do it...\n",
    "\n",
    "Read in the college dataset, group by state, and display the total number of groups. This should equal the number of unique states retrieved from the nunique Series method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college = pd.read_csv('data/college.csv', index_col='INSTNM')\n",
    "grouped = college.groupby('STABBR')\n",
    "grouped.ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301 µs ± 4.05 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit college['STABBR'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grouped variable has a filter method, which accepts a custom function that determines whether a group is kept or not. The custom function gets implicitly passed a DataFrame of the current group and is required to return a boolean. Let's define a function that calculates the total percentage of minority students and returns True if this percentage is greater than a user-defined threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_minority(df, threshold):\n",
    "    minority_pct = 1 - df['UGDS_WHITE']\n",
    "    total_minority = (df['UGDS'] * minority_pct).sum()\n",
    "    total_ugds = df['UGDS'].sum()\n",
    "    total_minority_pct = total_minority / total_ugds\n",
    "    return total_minority_pct > threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the filter method passed with the check_minority function and a threshold of 50% to find all states that have a minority majority:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>HBCU</th>\n",
       "      <th>MENONLY</th>\n",
       "      <th>WOMENONLY</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th>SATVRMID</th>\n",
       "      <th>SATMTMID</th>\n",
       "      <th>DISTANCEONLY</th>\n",
       "      <th>UGDS</th>\n",
       "      <th>...</th>\n",
       "      <th>UGDS_2MOR</th>\n",
       "      <th>UGDS_NRA</th>\n",
       "      <th>UGDS_UNKN</th>\n",
       "      <th>PPTUG_EF</th>\n",
       "      <th>CURROPER</th>\n",
       "      <th>PCTPELL</th>\n",
       "      <th>PCTFLOAN</th>\n",
       "      <th>UG25ABV</th>\n",
       "      <th>MD_EARN_WNE_P10</th>\n",
       "      <th>GRAD_DEBT_MDN_SUPP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INSTNM</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Everest College-Phoenix</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1026</td>\n",
       "      <td>0.4749</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8291</td>\n",
       "      <td>0.7151</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>28600</td>\n",
       "      <td>9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Collins College</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3855</td>\n",
       "      <td>0.3373</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7205</td>\n",
       "      <td>0.8228</td>\n",
       "      <td>0.4764</td>\n",
       "      <td>25700</td>\n",
       "      <td>47000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Empire Beauty School-Paradise Valley</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6349</td>\n",
       "      <td>0.5873</td>\n",
       "      <td>0.4651</td>\n",
       "      <td>17800</td>\n",
       "      <td>9588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Empire Beauty School-Tucson</th>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7962</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>0.4229</td>\n",
       "      <td>18200</td>\n",
       "      <td>9833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thunderbird School of Global Management</th>\n",
       "      <td>Glendale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>118900</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             CITY STABBR  HBCU  MENONLY  \\\n",
       "INSTNM                                                                    \n",
       "Everest College-Phoenix                   Phoenix     AZ   0.0      0.0   \n",
       "Collins College                           Phoenix     AZ   0.0      0.0   \n",
       "Empire Beauty School-Paradise Valley      Phoenix     AZ   0.0      0.0   \n",
       "Empire Beauty School-Tucson                Tucson     AZ   0.0      0.0   \n",
       "Thunderbird School of Global Management  Glendale     AZ   0.0      0.0   \n",
       "\n",
       "                                         WOMENONLY  RELAFFIL  SATVRMID  \\\n",
       "INSTNM                                                                   \n",
       "Everest College-Phoenix                        0.0         1       NaN   \n",
       "Collins College                                0.0         0       NaN   \n",
       "Empire Beauty School-Paradise Valley           0.0         1       NaN   \n",
       "Empire Beauty School-Tucson                    0.0         0       NaN   \n",
       "Thunderbird School of Global Management        0.0         0       NaN   \n",
       "\n",
       "                                         SATMTMID  DISTANCEONLY    UGDS  ...  \\\n",
       "INSTNM                                                                   ...   \n",
       "Everest College-Phoenix                       NaN           0.0  4102.0  ...   \n",
       "Collins College                               NaN           0.0    83.0  ...   \n",
       "Empire Beauty School-Paradise Valley          NaN           0.0    25.0  ...   \n",
       "Empire Beauty School-Tucson                   NaN           0.0   126.0  ...   \n",
       "Thunderbird School of Global Management       NaN           0.0     1.0  ...   \n",
       "\n",
       "                                         UGDS_2MOR  UGDS_NRA  UGDS_UNKN  \\\n",
       "INSTNM                                                                    \n",
       "Everest College-Phoenix                     0.0373       0.0     0.1026   \n",
       "Collins College                             0.0241       0.0     0.3855   \n",
       "Empire Beauty School-Paradise Valley        0.0400       0.0     0.0000   \n",
       "Empire Beauty School-Tucson                 0.0000       0.0     0.0079   \n",
       "Thunderbird School of Global Management     0.0000       0.0     0.0000   \n",
       "\n",
       "                                         PPTUG_EF  CURROPER  PCTPELL  \\\n",
       "INSTNM                                                                 \n",
       "Everest College-Phoenix                    0.4749         0   0.8291   \n",
       "Collins College                            0.3373         0   0.7205   \n",
       "Empire Beauty School-Paradise Valley       0.1600         0   0.6349   \n",
       "Empire Beauty School-Tucson                0.2222         1   0.7962   \n",
       "Thunderbird School of Global Management    1.0000         0   0.0000   \n",
       "\n",
       "                                         PCTFLOAN  UG25ABV  MD_EARN_WNE_P10  \\\n",
       "INSTNM                                                                        \n",
       "Everest College-Phoenix                    0.7151   0.6700            28600   \n",
       "Collins College                            0.8228   0.4764            25700   \n",
       "Empire Beauty School-Paradise Valley       0.5873   0.4651            17800   \n",
       "Empire Beauty School-Tucson                0.6615   0.4229            18200   \n",
       "Thunderbird School of Global Management    0.0000   0.0000           118900   \n",
       "\n",
       "                                         GRAD_DEBT_MDN_SUPP  \n",
       "INSTNM                                                       \n",
       "Everest College-Phoenix                                9500  \n",
       "Collins College                                       47000  \n",
       "Empire Beauty School-Paradise Valley                   9588  \n",
       "Empire Beauty School-Tucson                            9833  \n",
       "Thunderbird School of Global Management   PrivacySuppressed  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_filtered = grouped.filter(check_minority, threshold=.5)\n",
    "college_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just looking at the output may not be indicative of what actually happened. The DataFrame starts with state Arizona (AZ) and not Alaska (AK) so we can visually confirm that something changed. Let's compare the shape of this filtered DataFrame with the original. Looking at the results, about 60% of the rows have been filtered, and only 20 states remain that have a minority majority:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7535, 26)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3028, 26)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_filtered['STABBR'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works...\n",
    "\n",
    "This recipe takes a look at the total population of all the institutions on a state-by-state basis. The goal is to keep all the rows from the states, as a whole, that have a minority majority. This requires us to group our data by state, which is done in step 1. We find that there are 59 independent groups.\n",
    "\n",
    "The filter groupby method either keeps all the rows in a group or filters them out. It does not change the number of columns. The filter groupby method performs this gatekeeping through a user-defined function, for example, check_minority in this recipe. A very important aspect to filter is that it passes the entire DataFrame for that particular group to the user-defined function and returns a single boolean for each group.\n",
    "\n",
    "Inside of the check_minority function, the percentage and the total number of non-white students for each institution are first calculated and then the total number of all students is found. Finally, the percentage of non-white students for the entire state is checked against the given threshold, which produces a boolean.\n",
    "\n",
    "The final result is a DataFrame with the same columns as the original but with the rows from the states that don't meet the threshold filtered out. As it is possible that the head of the filtered DataFrame is the same as the original, you need to do some inspection to ensure that the operation completed successfully. We verify this by checking the number of rows and number of unique states.\n",
    "\n",
    "### There's more...\n",
    "\n",
    "Our function, check_minority, is flexible and accepts a parameter to lower or raise the percentage of minority threshold. Let's check the shape and number of unique states for a couple of other thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7461, 26)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_filtered_20 = grouped.filter(check_minority, threshold=.2)\n",
    "college_filtered_20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_filtered_20['STABBR'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(957, 26)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_filtered_70 = grouped.filter(check_minority, threshold=.7)\n",
    "college_filtered_70.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_filtered_70['STABBR'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 26)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_filtered_95 = grouped.filter(check_minority, threshold=.95)\n",
    "college_filtered_95.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming through a weight-loss \n",
    "One method to increase motivation to lose weight is to make a bet with someone else. The scenario in this recipe will track weight loss from two individuals over the course of a four-month period and determine a winner.\n",
    "\n",
    "### Getting ready\n",
    "\n",
    "In this recipe, we use simulated data from two individuals to track the percentage of weight loss over the course of four months. At the end of each month, a winner will be declared based on the individual who lost the highest percentage of body weight for that month. To track weight loss, we group our data by month and person, then call the transform method to find the percentage weight loss at each week from the start of the month.\n",
    "\n",
    "### How to do it...\n",
    "\n",
    "Read in the raw weight_loss dataset, and examine the first month of data from the two people, Amy and Bob. There are a total of four weigh-ins per month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Name Month    Week  Weight\n",
       "0  Bob   Jan  Week 1     291\n",
       "1  Amy   Jan  Week 1     197\n",
       "2  Bob   Jan  Week 2     288\n",
       "3  Amy   Jan  Week 2     189\n",
       "4  Bob   Jan  Week 3     283\n",
       "5  Amy   Jan  Week 3     189\n",
       "6  Bob   Jan  Week 4     283\n",
       "7  Amy   Jan  Week 4     190"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_loss = pd.read_csv('data/weight_loss.csv')\n",
    "weight_loss.query('Month == \"Jan\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the winner for each month, we only need to compare weight loss from the first week to the last week of each month. But, if we wanted to have weekly updates, we can also calculate weight loss from the current week to the first week of each month.  Let's create a function that is capable of providing weekly updates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_perc_loss(s):\n",
    "    return (s - s.iloc[0]) / s.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.000000\n",
       "2   -0.010309\n",
       "4   -0.027491\n",
       "6   -0.027491\n",
       "Name: Weight, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_jan = weight_loss.query('Name==\"Bob\" and Month==\"Jan\"')\n",
    "find_perc_loss(bob_jan['Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the first week, Bob lost 1% of his body weight. He continued losing weight during the second week but made no progress during the last week.  We can apply this function to every single combination of person and week to get the weight loss per week in relation to the first week of the month. To do this, we need to group our data by Name and Month , and then use the transform method to apply this custom function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.000000\n",
       "1    0.000000\n",
       "2   -0.010309\n",
       "3   -0.040609\n",
       "4   -0.027491\n",
       "5   -0.040609\n",
       "6   -0.027491\n",
       "7   -0.035533\n",
       "Name: Weight, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_weight_loss = weight_loss.groupby(['Name', 'Month'])['Weight'].transform(find_perc_loss)\n",
    "per_weight_loss.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transform method must return an object with the same number of rows as the calling DataFrame. Let's append this result to our original DataFrame as a new column. To help shorten the output, we will select Bob's first two months of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Perc Weight Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>291</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>288</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>283</td>\n",
       "      <td>-0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>283</td>\n",
       "      <td>-0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>283</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>275</td>\n",
       "      <td>-0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>268</td>\n",
       "      <td>-0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>268</td>\n",
       "      <td>-0.053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name Month    Week  Weight  Perc Weight Loss\n",
       "0   Bob   Jan  Week 1     291             0.000\n",
       "2   Bob   Jan  Week 2     288            -0.010\n",
       "4   Bob   Jan  Week 3     283            -0.027\n",
       "6   Bob   Jan  Week 4     283            -0.027\n",
       "8   Bob   Feb  Week 1     283             0.000\n",
       "10  Bob   Feb  Week 2     275            -0.028\n",
       "12  Bob   Feb  Week 3     268            -0.053\n",
       "14  Bob   Feb  Week 4     268            -0.053"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_loss['Perc Weight Loss'] = per_weight_loss.round(3)\n",
    "weight_loss.query('Name==\"Bob\" and Month in [\"Jan\", \"Feb\"]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the percentage weight loss resets after the new month. With this new column, we can manually determine a winner but let's see if we can find a way to do this automatically. As the only week that matters is the last week, let's select week 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Perc Weight Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>283</td>\n",
       "      <td>-0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>190</td>\n",
       "      <td>-0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>268</td>\n",
       "      <td>-0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>173</td>\n",
       "      <td>-0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>261</td>\n",
       "      <td>-0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>170</td>\n",
       "      <td>-0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>250</td>\n",
       "      <td>-0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>161</td>\n",
       "      <td>-0.053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name Month    Week  Weight  Perc Weight Loss\n",
       "6   Bob   Jan  Week 4     283            -0.027\n",
       "7   Amy   Jan  Week 4     190            -0.036\n",
       "14  Bob   Feb  Week 4     268            -0.053\n",
       "15  Amy   Feb  Week 4     173            -0.089\n",
       "22  Bob   Mar  Week 4     261            -0.026\n",
       "23  Amy   Mar  Week 4     170            -0.017\n",
       "30  Bob   Apr  Week 4     250            -0.042\n",
       "31  Amy   Apr  Week 4     161            -0.053"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week4 = weight_loss.query('Week == \"Week 4\"')\n",
    "week4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This narrows down the weeks but still doesn't automatically find out the winner of each month. Let's reshape this data with the pivot method so that Bob's and Amy's percent weight loss is side-by-side for each month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Name</th>\n",
       "      <th>Amy</th>\n",
       "      <th>Bob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Apr</th>\n",
       "      <td>-0.053</td>\n",
       "      <td>-0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feb</th>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jan</th>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mar</th>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Name     Amy    Bob\n",
       "Month              \n",
       "Apr   -0.053 -0.042\n",
       "Feb   -0.089 -0.053\n",
       "Jan   -0.036 -0.027\n",
       "Mar   -0.017 -0.026"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winner = week4.pivot(index='Month', columns='Name', values='Perc Weight Loss')\n",
    "winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output makes it clearer who has won each month, but we can still go a couple steps farther. NumPy has a vectorized if-then-else function called where, which can map a Series or array of booleans to other values. Let's create a column for the name of the winner and highlight the winning percentage for each month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\IPython\\core\\formatters.py:344\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    342\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 344\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\io\\formats\\style.py:408\u001b[0m, in \u001b[0;36mStyler._repr_html_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03mHooks into Jupyter notebook rich display system, which calls _repr_html_ by\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;124;03mdefault if an object is returned at the end of a cell.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyler.render.repr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\io\\formats\\style.py:1348\u001b[0m, in \u001b[0;36mStyler.to_html\u001b[1;34m(self, buf, table_uuid, table_attributes, sparse_index, sparse_columns, bold_headers, caption, max_rows, max_columns, encoding, doctype_html, exclude_styles, **kwargs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m     obj\u001b[38;5;241m.\u001b[39mset_caption(caption)\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;66;03m# Build HTML string..\u001b[39;00m\n\u001b[1;32m-> 1348\u001b[0m html \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_render_html(\n\u001b[0;32m   1349\u001b[0m     sparse_index\u001b[38;5;241m=\u001b[39msparse_index,\n\u001b[0;32m   1350\u001b[0m     sparse_columns\u001b[38;5;241m=\u001b[39msparse_columns,\n\u001b[0;32m   1351\u001b[0m     max_rows\u001b[38;5;241m=\u001b[39mmax_rows,\n\u001b[0;32m   1352\u001b[0m     max_cols\u001b[38;5;241m=\u001b[39mmax_columns,\n\u001b[0;32m   1353\u001b[0m     exclude_styles\u001b[38;5;241m=\u001b[39mexclude_styles,\n\u001b[0;32m   1354\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding \u001b[38;5;129;01mor\u001b[39;00m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyler.render.encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1355\u001b[0m     doctype_html\u001b[38;5;241m=\u001b[39mdoctype_html,\n\u001b[0;32m   1356\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1357\u001b[0m )\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m save_to_buffer(\n\u001b[0;32m   1360\u001b[0m     html, buf\u001b[38;5;241m=\u001b[39mbuf, encoding\u001b[38;5;241m=\u001b[39m(encoding \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1361\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\io\\formats\\style_render.py:204\u001b[0m, in \u001b[0;36mStylerRenderer._render_html\u001b[1;34m(self, sparse_index, sparse_columns, max_rows, max_cols, **kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_render_html\u001b[39m(\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    194\u001b[0m     sparse_index: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    199\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    200\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    Renders the ``Styler`` including all applied styles to HTML.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m    Generates a dict with necessary kwargs passed to jinja2 template.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 204\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparse_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m&nbsp;\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m     d\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate_html\u001b[38;5;241m.\u001b[39mrender(\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39md,\n\u001b[0;32m    208\u001b[0m         html_table_tpl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate_html_table,\n\u001b[0;32m    209\u001b[0m         html_style_tpl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate_html_style,\n\u001b[0;32m    210\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\io\\formats\\style_render.py:161\u001b[0m, in \u001b[0;36mStylerRenderer._render\u001b[1;34m(self, sparse_index, sparse_columns, max_rows, max_cols, blank)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_render\u001b[39m(\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    149\u001b[0m     sparse_index: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    153\u001b[0m     blank: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    154\u001b[0m ):\n\u001b[0;32m    155\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    Computes and applies styles and then generates the general render dicts.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    Also extends the `ctx` and `ctx_index` attributes with those of concatenated\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;124;03m    stylers for use within `_translate_latex`\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m     dxs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    163\u001b[0m     ctx_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\io\\formats\\style_render.py:256\u001b[0m, in \u001b[0;36mStylerRenderer._compute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_todo:\n\u001b[1;32m--> 256\u001b[0m     r \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\io\\formats\\style.py:1731\u001b[0m, in \u001b[0;36mStyler._apply\u001b[1;34m(self, func, axis, subset, **kwargs)\u001b[0m\n\u001b[0;32m   1729\u001b[0m         result \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mapply(func, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1730\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1731\u001b[0m         result \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mapply(func, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mT  \u001b[38;5;66;03m# see GH 42005\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1735\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(func)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m resulted in the apply method collapsing to a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1736\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mUsually, this is the result of the function returning a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1737\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle value, instead of list-like.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1738\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\frame.py:10034\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m  10022\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10024\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10025\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10026\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10032\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10033\u001b[0m )\n\u001b[1;32m> 10034\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\apply.py:837\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\apply.py:965\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 965\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\apply.py:981\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    980\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    983\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    984\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    985\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\io\\formats\\style.py:3935\u001b[0m, in \u001b[0;36m_highlight_value\u001b[1;34m(data, op, props)\u001b[0m\n\u001b[0;32m   3931\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_highlight_value\u001b[39m(data: DataFrame \u001b[38;5;241m|\u001b[39m Series, op: \u001b[38;5;28mstr\u001b[39m, props: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m   3932\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3933\u001b[0m \u001b[38;5;124;03m    Return an array of css strings based on the condition of values matching an op.\u001b[39;00m\n\u001b[0;32m   3934\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3935\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   3936\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, DataFrame):  \u001b[38;5;66;03m# min/max must be done twice to return scalar\u001b[39;00m\n\u001b[0;32m   3937\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(value, op)(skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\series.py:6183\u001b[0m, in \u001b[0;36mSeries.min\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   6175\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   6176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmin\u001b[39m(\n\u001b[0;32m   6177\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6181\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   6182\u001b[0m ):\n\u001b[1;32m-> 6183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\generic.py:11960\u001b[0m, in \u001b[0;36mNDFrame.min\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11953\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmin\u001b[39m(\n\u001b[0;32m  11954\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11955\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11958\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11959\u001b[0m ):\n\u001b[1;32m> 11960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  11961\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m  11962\u001b[0m         nanops\u001b[38;5;241m.\u001b[39mnanmin,\n\u001b[0;32m  11963\u001b[0m         axis,\n\u001b[0;32m  11964\u001b[0m         skipna,\n\u001b[0;32m  11965\u001b[0m         numeric_only,\n\u001b[0;32m  11966\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11967\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\generic.py:11949\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11945\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[0;32m  11947\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 11949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  11951\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\series.py:6133\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   6128\u001b[0m     \u001b[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001b[39;00m\n\u001b[0;32m   6129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   6130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6132\u001b[0m     )\n\u001b[1;32m-> 6133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\nanops.py:1092\u001b[0m, in \u001b[0;36m_nanminmax.<locals>.reduction\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m   1087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _na_for_min_count(values, axis)\n\u001b[0;32m   1089\u001b[0m values, mask \u001b[38;5;241m=\u001b[39m _get_values(\n\u001b[0;32m   1090\u001b[0m     values, skipna, fill_value_typ\u001b[38;5;241m=\u001b[39mfill_value_typ, mask\u001b[38;5;241m=\u001b[39mmask\n\u001b[0;32m   1091\u001b[0m )\n\u001b[1;32m-> 1092\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1093\u001b[0m result \u001b[38;5;241m=\u001b[39m _maybe_null_out(result, axis, mask, values\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\numpy\\core\\_methods.py:45\u001b[0m, in \u001b[0;36m_amin\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     44\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_minimum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<=' not supported between instances of 'float' and 'str'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d7f1942050>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winner['Winner'] = np.where(winner['Amy'] < winner['Bob'], 'Amy', 'Bob')\n",
    "winner.style.highlight_min(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the value_counts method to return the final score as the number of months won:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Winner\n",
       "Amy    3\n",
       "Bob    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winner.Winner.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works...\n",
    "\n",
    "Throughout this recipe, the query method is used to filter data instead of boolean indexing. Refer to the Improving readability of Boolean indexing with the query method recipe from Chapter 5, Boolean Indexing, for more information.\n",
    "\n",
    "Our goal is to find the percentage weight loss for each month for each person. One way to accomplish this task is to calculate each week's weight loss relative to the start of each month. This specific task is perfectly suited to the transformgroupby method. The transform method accepts a function as its one required parameter. This function gets implicitly passed each non-grouping column (or only the columns specified in the indexing operator as was done in this recipe with Weight). It must return a sequence of values the same length as the passed group or else an exception will be raised. In essence, all values from the original DataFrame are transforming. No aggregation or filtration takes place.\n",
    "\n",
    "Step 2 creates a function that subtracts the first value of the passed Series from all of its values and then divides this result by the first value. This calculates the percent loss (or gain) relative to the first value. In step 3 we test this function on one person during one month.\n",
    "\n",
    "In step 4, we use this function in the same manner over every combination of person and week. In some literal sense, we are transforming the Weight column into the percentage of weight lost for the current week. The first month of data is outputted for each person. Pandas returns the new data as a Series. This Series isn't all that useful by itself and makes more sense appended to the original DataFrame as a new column. We complete this operation in step 5.\n",
    "\n",
    "To determine the winner, only week 4 of each month is necessary. We could stop here and manually determine the winner but pandas supplies us functionality to automate this. The pivot function in step 7 reshapes our dataset by pivoting the unique values of one column into new column names. The index parameter is used for the column that you do not want to pivot. The column passed to the values parameter gets tiled over each unique combination of the columns in the index and columns parameters.\n",
    "\n",
    "**Note**\n",
    "\n",
    "The pivot method only works if there is just a single occurrence of each unique combination of the columns in the index and columns parameters. If there is more than one unique combination, an exception will be raised. You can use the pivot_table method in that situation which allows you to aggregate multiple values together.\n",
    "\n",
    "After pivoting, we utilize the highly effective and fast NumPy where function, whose first argument is a condition that produces a Series of booleans. True values get mapped to Amy and False values get mapped to Bob. We highlight the winner of each month and tally the final score with the value_counts method.\n",
    "\n",
    "### There's more...\n",
    "\n",
    "Take a look at the DataFrame output from step 7. Did you notice that the months are in alphabetical and not chronological order? Pandas unfortunately, in this case at least, orders the months for us alphabetically. We can solve this issue by changing the data type of Month to a categorical variable. Categorical variables map all the values of each column to an integer. We can choose this mapping to be the normal chronological order for the months. Pandas uses this underlying integer mapping during the pivot method to order the months chronologically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Jan', 'Feb', 'Mar', 'Apr'], dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week4a = week4.copy()\n",
    "month_chron = week4a['Month'].unique() # or month.drop_duplicates\n",
    "month_chron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Name</th>\n",
       "      <th>Amy</th>\n",
       "      <th>Bob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jan</th>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feb</th>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mar</th>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apr</th>\n",
       "      <td>-0.053</td>\n",
       "      <td>-0.042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Name     Amy    Bob\n",
       "Month              \n",
       "Jan   -0.036 -0.027\n",
       "Feb   -0.089 -0.053\n",
       "Mar   -0.017 -0.026\n",
       "Apr   -0.053 -0.042"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week4a['Month'] = pd.Categorical(week4a['Month'], categories=month_chron)\n",
    "week4a.pivot(index='Month', columns='Name', values='Perc Weight Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the Month column, use the Categorical constructor. Pass it the original column as a Series and a unique sequence of all the categories in the desired order to the categories parameter. As the Month column is already in chronological order, we can simply use the unique method, which preserves order to get the array that we desire. In general, to sort columns of object data type by something other than alphabetical, convert them to categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating weighted mean SAT scores per state with apply\n",
    "The groupby object has four methods that accept a function (or functions) to perform a calculation on each group. These four methods are agg, filter, transform, and apply. Each of the first three of these methods has a very specific output that the function must return. agg must return a scalar value, filter must return a boolean, and transform must return a Series with the same length as the passed group. The apply method, however, may return a scalar value, a Series, or even a DataFrame of any shape, therefore making it very flexible. It is also called only once per group, which contrasts with transform and agg that get called once for each non-grouping column. The apply method's ability to return a single object when operating on multiple columns at the same time makes the calculation in this recipe possible.\n",
    "\n",
    "### Getting ready\n",
    "\n",
    "`In this recipe, we calculate the weighted average of both the math and verbal SAT scores per state from the college dataset. We weight the scores by the population of undergraduate students per school.`\n",
    "\n",
    "### How to do it...\n",
    "\n",
    "Read in the college dataset, and drop any rows that have missing values in either the UGDS, SATMTMID, or SATVRMID columns. We must have non-missing values for each of these three columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7535, 27)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college = pd.read_csv('data/college.csv')\n",
    "college2 = college.dropna(subset=['UGDS', 'SATMTMID', 'SATVRMID'])\n",
    "college.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1184, 27)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vast majority of institutions do not have data for our three required columns, but this is still more than enough data to continue. Next, create a user-defined function to calculate the weighted average of just the SAT math scores:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_math_average(df):\n",
    "    weighted_math = df['UGDS'] * df['SATMTMID']\n",
    "    return int(weighted_math.sum() / df['UGDS'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by state and pass this function to the apply method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STABBR\n",
       "AK    503\n",
       "AL    536\n",
       "AR    529\n",
       "AZ    569\n",
       "CA    564\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college2.groupby('STABBR').apply(weighted_math_average).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We successfully returned a scalar value for each group. Let's take a small detour and see what the outcome would have been by passing the same function to the agg method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'UGDS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:160\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'UGDS'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:292\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_agg_general(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;66;03m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;66;03m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:325\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\n\u001b[1;32m--> 325\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m res \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_constructor(result, name\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:849\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    847\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 849\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:877\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m--> 877\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    878\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:322\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    321\u001b[0m     warn_alias_replacement(\u001b[38;5;28mself\u001b[39m, orig_func, alias)\n\u001b[1;32m--> 322\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: func(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    324\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\n",
      "Cell \u001b[1;32mIn[83], line 2\u001b[0m, in \u001b[0;36mweighted_math_average\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweighted_math_average\u001b[39m(df):\n\u001b[1;32m----> 2\u001b[0m     weighted_math \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUGDS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSATMTMID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(weighted_math\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUGDS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'UGDS'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:160\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'UGDS'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcollege2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSTABBR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweighted_math_average\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:1495\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1493\u001b[0m gba \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, [func], args\u001b[38;5;241m=\u001b[39m(), kwargs\u001b[38;5;241m=\u001b[39m{})\n\u001b[0;32m   1494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1495\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mgba\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1498\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\apply.py:178\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_dict_like()\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[0;32m    181\u001b[0m     f \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mget_cython_func(func)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\apply.py:311\u001b[0m, in \u001b[0;36mApply.agg_list_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magg_list_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    304\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    Compute aggregation in the case of a list-like argument.\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    Result of aggregation.\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_or_apply_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43magg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\apply.py:1353\u001b[0m, in \u001b[0;36mGroupByApply.agg_or_apply_list_like\u001b[1;34m(self, op_name)\u001b[0m\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;66;03m# Only set as_index=True on groupby objects, not Window or Resample\u001b[39;00m\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;66;03m# that inherit from this class.\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m com\u001b[38;5;241m.\u001b[39mtemp_setattr(\n\u001b[0;32m   1351\u001b[0m     obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1352\u001b[0m ):\n\u001b[1;32m-> 1353\u001b[0m     keys, results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1354\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results_list_like(keys, results)\n\u001b[0;32m   1355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\apply.py:370\u001b[0m, in \u001b[0;36mApply.compute_list_like\u001b[1;34m(self, op_name, selected_obj, kwargs)\u001b[0m\n\u001b[0;32m    364\u001b[0m colg \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_gotitem(col, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, subset\u001b[38;5;241m=\u001b[39mselected_obj\u001b[38;5;241m.\u001b[39miloc[:, index])\n\u001b[0;32m    365\u001b[0m args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    366\u001b[0m     [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs]\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m include_axis(op_name, colg)\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\n\u001b[0;32m    369\u001b[0m )\n\u001b[1;32m--> 370\u001b[0m new_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(colg, op_name)(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    371\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(new_res)\n\u001b[0;32m    372\u001b[0m indices\u001b[38;5;241m.\u001b[39mappend(index)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:255\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine\n\u001b[0;32m    254\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[1;32m--> 255\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_multiple_funcs(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;66;03m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:360\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_multiple_funcs\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, func) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arg):\n\u001b[0;32m    359\u001b[0m         key \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mOutputKey(label\u001b[38;5;241m=\u001b[39mname, position\u001b[38;5;241m=\u001b[39midx)\n\u001b[1;32m--> 360\u001b[0m         results[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, DataFrame) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:297\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_agg_general(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;66;03m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;66;03m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n\u001b[1;32m--> 297\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_named(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    299\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPinning the groupby key to each group in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.agg is deprecated, and cases that \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    307\u001b[0m     )\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;66;03m# result is a dict whose keys are the elements of result_index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:459\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_named\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis\n\u001b[0;32m    455\u001b[0m ):\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;66;03m# needed for pandas/tests/groupby/test_groupby.py::test_basic_aggregations\u001b[39;00m\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(group, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[1;32m--> 459\u001b[0m     output \u001b[38;5;241m=\u001b[39m func(group, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    460\u001b[0m     output \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mextract_result(output)\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[83], line 2\u001b[0m, in \u001b[0;36mweighted_math_average\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweighted_math_average\u001b[39m(df):\n\u001b[1;32m----> 2\u001b[0m     weighted_math \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUGDS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSATMTMID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(weighted_math\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUGDS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'UGDS'"
     ]
    }
   ],
   "source": [
    "college2.groupby('STABBR').agg(weighted_math_average).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted_math_average function gets applied to each non-aggregating column in the DataFrame. If you try and limit the columns to just SATMTMID, you will get an error as you won't have access to UGDS. So, the best way to complete operations that act on multiple columns is with apply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'UGDS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:160\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'UGDS'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:292\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_agg_general(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;66;03m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;66;03m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:325\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\n\u001b[1;32m--> 325\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m res \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_constructor(result, name\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:849\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    847\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 849\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:877\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m--> 877\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    878\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:322\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    321\u001b[0m     warn_alias_replacement(\u001b[38;5;28mself\u001b[39m, orig_func, alias)\n\u001b[1;32m--> 322\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: func(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    324\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\n",
      "Cell \u001b[1;32mIn[83], line 2\u001b[0m, in \u001b[0;36mweighted_math_average\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweighted_math_average\u001b[39m(df):\n\u001b[1;32m----> 2\u001b[0m     weighted_math \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUGDS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSATMTMID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(weighted_math\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUGDS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'UGDS'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:160\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'UGDS'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcollege2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSTABBR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSATMTMID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweighted_math_average\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:297\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_agg_general(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;66;03m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;66;03m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n\u001b[1;32m--> 297\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_named(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    299\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPinning the groupby key to each group in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.agg is deprecated, and cases that \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    307\u001b[0m     )\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;66;03m# result is a dict whose keys are the elements of result_index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:459\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_named\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis\n\u001b[0;32m    455\u001b[0m ):\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;66;03m# needed for pandas/tests/groupby/test_groupby.py::test_basic_aggregations\u001b[39;00m\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(group, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[1;32m--> 459\u001b[0m     output \u001b[38;5;241m=\u001b[39m func(group, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    460\u001b[0m     output \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mextract_result(output)\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[83], line 2\u001b[0m, in \u001b[0;36mweighted_math_average\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweighted_math_average\u001b[39m(df):\n\u001b[1;32m----> 2\u001b[0m     weighted_math \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUGDS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSATMTMID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(weighted_math\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUGDS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'UGDS'"
     ]
    }
   ],
   "source": [
    "college2.groupby('STABBR')['SATMTMID'].agg(weighted_math_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice feature of apply is that you can create multiple new columns by returning a Series. The index of this returned Series will be the new column names. Let's modify our function to calculate the weighted and arithmetic average for both SAT scores along with the count of the number of institutions from each group. We return these five values in a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Trying to coerce float values to integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries(data, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mcollege2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSTABBR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweighted_average\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1770\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1769\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1770\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   1772\u001b[0m         \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[0;32m   1773\u001b[0m         \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1777\u001b[0m         \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[0;32m   1778\u001b[0m         \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_apply_general(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1819\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[1;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[0;32m   1784\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[0;32m   1786\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1791\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1792\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[0;32m   1795\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1817\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[0;32m   1818\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1819\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_groupwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1820\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1821\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:911\u001b[0m, in \u001b[0;36mBaseGrouper.apply_groupwise\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[0;32m    910\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[1;32m--> 911\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[0;32m    913\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[87], line 12\u001b[0m, in \u001b[0;36mweighted_average\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     10\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbal_avg\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSATVRMID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     11\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df)\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mint\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\series.py:475\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    473\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39m_mgr\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_dict_like(data):\n\u001b[1;32m--> 475\u001b[0m     data, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    477\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\series.py:568\u001b[0m, in \u001b[0;36mSeries._init_dict\u001b[1;34m(self, data, index, dtype)\u001b[0m\n\u001b[0;32m    565\u001b[0m     keys, values \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;241m0\u001b[39m), []\n\u001b[0;32m    567\u001b[0m \u001b[38;5;66;03m# Input is now list-like, so rely on \"standard\" construction:\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;66;03m# Now we just make sure the order is respected, if any\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\series.py:512\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    510\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 512\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    514\u001b[0m     manager \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\construction.py:650\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    647\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_try_cast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    653\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m maybe_convert_platform(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\construction.py:814\u001b[0m, in \u001b[0;36m_try_cast\u001b[1;34m(arr, dtype, copy)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;66;03m# GH#15832: Check if we are requesting a numeric dtype and\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# that we can convert the data to the requested dtype.\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;66;03m# this will raise if we have e.g. floats\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_cast_to_integer_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    816\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(arr, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1662\u001b[0m, in \u001b[0;36mmaybe_cast_to_integer_array\u001b[1;34m(arr, dtype)\u001b[0m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(arr)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m   1659\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IntCastingNaNError(\n\u001b[0;32m   1660\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1661\u001b[0m         )\n\u001b[1;32m-> 1662\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to coerce float values to integers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m   1664\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to coerce float values to integers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Trying to coerce float values to integers"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "def weighted_average(df):\n",
    "    data = OrderedDict()\n",
    "    weighted_math = df['UGDS'] * df['SATMTMID']\n",
    "    weighted_verbal = df['UGDS'] * df['SATVRMID']\n",
    "    \n",
    "    data['weighted_math_avg'] = weighted_math.sum() / df['UGDS'].sum()\n",
    "    data['weighted_verbal_avg'] = weighted_verbal.sum() / df['UGDS'].sum()\n",
    "    data['math_avg'] = df['SATMTMID'].mean()\n",
    "    data['verbal_avg'] = df['SATVRMID'].mean()\n",
    "    data['count'] = len(df)\n",
    "    return pd.Series(data, dtype='int')\n",
    "\n",
    "college2.groupby('STABBR').apply(weighted_average).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works...\n",
    "\n",
    "In order for this recipe to complete properly, we need to first filter for institutions that do not have missing values for UGDS, SATMTMID, and SATVRMID. By default, the dropna method drops rows that have one or more missing values. We must use the subset parameter to limit the columns it looks at for missing values.\n",
    "\n",
    "In step 2, we define a function that calculates the weighted average for just the SATMTMID column. The weighted average differs from an arithmetic mean in that each value is multiplied by some weight. This quantity is then summed and divided by the sum of the weights. In this case, our weight is the undergraduate student population.\n",
    "\n",
    "In step 3, we pass this function to the apply method. Our function weighted_math_average gets passed a DataFrame of all the original columns for each group. It returns a single scalar value, the weighted average of SATMTMID. At this point, you might think that this calculation is possible using the agg method. Directly replacing apply with agg does not work as agg returns a value for each of its aggregating columns.\n",
    "\n",
    "**Note**\n",
    "\n",
    "It actually is possible to use agg indirectly by precomputing the multiplication of UGDS and SATMTMID.\n",
    "\n",
    "Step 6 really shows the versatility of apply. We build a new function that calculates the weighted and arithmetic average of both SAT columns as well as the number of rows for each group. In order for apply to create multiple columns, you must return a Series. The index values are used as column names in the resulting DataFrame. You can return as many values as you want with this method.\n",
    "\n",
    "Notice that the OrderedDict class was imported from the collections module, which is part of the standard library. This ordered dictionary is used to store the data. A normal Python dictionary could not have been used to store the data since it does not preserve insertion order.\n",
    "\n",
    "**Note**\n",
    "\n",
    "The constructor, pd.Series, does have an index parameter that you can use to specify order but using an OrderedDict is cleaner.\n",
    "\n",
    "### There's more...\n",
    "\n",
    "In this recipe, we returned a single row as a Series for each group. It's possible to return any number of rows and columns for each group by returning a DataFrame. In addition to finding just the arithmetic and weighted means, let's also find the geometric and harmonic means of both SAT columns and return the results as a DataFrame with rows as the name of the type of mean and columns as the SAT type. To ease the burden on us, we use the NumPy function average to compute the weighted average and the SciPy functions gmean and hmean for geometric and harmonic means:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SATMTMID</th>\n",
       "      <th>SATVRMID</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABBR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">AL</th>\n",
       "      <th>Arithmetic</th>\n",
       "      <td>504</td>\n",
       "      <td>508</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted</th>\n",
       "      <td>536</td>\n",
       "      <td>533</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geometric</th>\n",
       "      <td>500</td>\n",
       "      <td>505</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harmonic</th>\n",
       "      <td>497</td>\n",
       "      <td>502</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">AR</th>\n",
       "      <th>Arithmetic</th>\n",
       "      <td>515</td>\n",
       "      <td>491</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted</th>\n",
       "      <td>529</td>\n",
       "      <td>504</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geometric</th>\n",
       "      <td>514</td>\n",
       "      <td>489</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harmonic</th>\n",
       "      <td>513</td>\n",
       "      <td>487</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AZ</th>\n",
       "      <th>Arithmetic</th>\n",
       "      <td>536</td>\n",
       "      <td>538</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted</th>\n",
       "      <td>569</td>\n",
       "      <td>557</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   SATMTMID  SATVRMID  count\n",
       "STABBR                                      \n",
       "AL     Arithmetic       504       508     21\n",
       "       Weighted         536       533     21\n",
       "       Geometric        500       505     21\n",
       "       Harmonic         497       502     21\n",
       "AR     Arithmetic       515       491     16\n",
       "       Weighted         529       504     16\n",
       "       Geometric        514       489     16\n",
       "       Harmonic         513       487     16\n",
       "AZ     Arithmetic       536       538      6\n",
       "       Weighted         569       557      6"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import gmean, hmean\n",
    "def calculate_means(df):\n",
    "    df_means = pd.DataFrame(index=['Arithmetic', 'Weighted', 'Geometric', 'Harmonic'])\n",
    "    cols = ['SATMTMID', 'SATVRMID']\n",
    "    for col in cols:\n",
    "        arithmetic = df[col].mean()\n",
    "        weighted = np.average(df[col], weights=df['UGDS'])\n",
    "        geometric = gmean(df[col])\n",
    "        harmonic = hmean(df[col])\n",
    "        df_means[col] = [arithmetic, weighted, geometric, harmonic]\n",
    "        \n",
    "    df_means['count'] = len(df)\n",
    "    return df_means.astype(int)\n",
    "\n",
    "college2.groupby('STABBR').filter(lambda x: len(x) != 1).groupby('STABBR').apply(calculate_means).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping by continuous variables\n",
    "\n",
    "When grouping in pandas, you typically use columns with discrete repeating values. If there are no repeated values, then grouping would be pointless as there would only be one row per group. Continuous numeric columns typically have few repeated values and are generally not used to form groups. However, if we can transform columns with continuous values into a discrete column by placing each value into a bin, rounding them, or using some other mapping, then grouping with them makes sense.\n",
    "\n",
    "### Getting ready\n",
    "\n",
    "In this recipe, we explore the flights dataset to discover the distribution of airlines for different travel distances. This allows us, for example, to find the airline that makes the most flights between 500 and 1,000 miles. To accomplish this, we use the pandas cut function to discretize the distance of each flight flown.\n",
    "\n",
    "### How to do it...\n",
    "\n",
    "Read in the flights dataset, and output the first five rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>ORG_AIR</th>\n",
       "      <th>DEST_AIR</th>\n",
       "      <th>SCHED_DEP</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DIST</th>\n",
       "      <th>SCHED_ARR</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>SLC</td>\n",
       "      <td>1625</td>\n",
       "      <td>58.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>590</td>\n",
       "      <td>1905</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>UA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>IAD</td>\n",
       "      <td>823</td>\n",
       "      <td>7.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1452</td>\n",
       "      <td>1333</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>MQ</td>\n",
       "      <td>DFW</td>\n",
       "      <td>VPS</td>\n",
       "      <td>1305</td>\n",
       "      <td>36.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>641</td>\n",
       "      <td>1453</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>DCA</td>\n",
       "      <td>1555</td>\n",
       "      <td>7.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1192</td>\n",
       "      <td>1935</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1720</td>\n",
       "      <td>48.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1363</td>\n",
       "      <td>2225</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MONTH  DAY  WEEKDAY AIRLINE ORG_AIR DEST_AIR  SCHED_DEP  DEP_DELAY  \\\n",
       "0      1    1        4      WN     LAX      SLC       1625       58.0   \n",
       "1      1    1        4      UA     DEN      IAD        823        7.0   \n",
       "2      1    1        4      MQ     DFW      VPS       1305       36.0   \n",
       "3      1    1        4      AA     DFW      DCA       1555        7.0   \n",
       "4      1    1        4      WN     LAX      MCI       1720       48.0   \n",
       "\n",
       "   AIR_TIME  DIST  SCHED_ARR  ARR_DELAY  DIVERTED  CANCELLED  \n",
       "0      94.0   590       1905       65.0         0          0  \n",
       "1     154.0  1452       1333      -13.0         0          0  \n",
       "2      85.0   641       1453       35.0         0          0  \n",
       "3     126.0  1192       1935       -7.0         0          0  \n",
       "4     166.0  1363       2225       39.0         0          0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights = pd.read_csv('data/flights.csv')\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.wunderground.com/history/airport/KDFW/2015/2/27/DailyHistory.html?req_city=Dallas-Fort+Worth+International&req_state=TX&req_statename=Texas&reqdb.zip=75261&reqdb.magic=5&reqdb.wmo=99999&MR=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.DIST.hasnans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58492, 14)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.dropna(subset=['DIST']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to find the distribution of airlines over a range of distances, we need to place the values of the DIST column into discrete bins. Let's use the pandas cut function to split the data into five bins:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     (500.0, 1000.0]\n",
       "1    (1000.0, 2000.0]\n",
       "2     (500.0, 1000.0]\n",
       "3    (1000.0, 2000.0]\n",
       "4    (1000.0, 2000.0]\n",
       "Name: DIST, dtype: category\n",
       "Categories (5, interval[float64, right]): [(-inf, 200.0] < (200.0, 500.0] < (500.0, 1000.0] < (1000.0, 2000.0] < (2000.0, inf]]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [-np.inf, 200, 500, 1000, 2000, np.inf]\n",
    "cuts = pd.cut(flights['DIST'], bins=bins)\n",
    "cuts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ordered categorical Series is created. To help get an idea of what happened, let's count the values of each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIST\n",
       "(500.0, 1000.0]     20659\n",
       "(200.0, 500.0]      15874\n",
       "(1000.0, 2000.0]    14186\n",
       "(2000.0, inf]        4054\n",
       "(-inf, 200.0]        3719\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuts.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cuts Series can now be used to form groups. Pandas allows you to form groups in any way you wish. Pass the cuts Series to the groupby method and then call the value_counts method on the AIRLINE column to find the distribution for each distance group. Notice that SkyWest (OO) makes up 33% of flights less than 200 miles but only 16% of those between 200 and 500 miles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumanth\\AppData\\Local\\Temp\\ipykernel_8552\\1498986617.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  flights.groupby(cuts)['AIRLINE'].value_counts(normalize=True).round(3).head(15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DIST            AIRLINE\n",
       "(-inf, 200.0]   OO         0.326\n",
       "                EV         0.289\n",
       "                MQ         0.211\n",
       "                DL         0.086\n",
       "                AA         0.052\n",
       "                UA         0.027\n",
       "                WN         0.009\n",
       "                US         0.000\n",
       "                AS         0.000\n",
       "                NK         0.000\n",
       "                HA         0.000\n",
       "                F9         0.000\n",
       "                B6         0.000\n",
       "                VX         0.000\n",
       "(200.0, 500.0]  WN         0.194\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.groupby(cuts)['AIRLINE'].value_counts(normalize=True).round(3).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works...\n",
    "\n",
    "In step 2, the cut function places each value of the DIST column into one of five bins. The bins are created by a sequence of six numbers defining the edges. You always need one more edge than the number of bins. You can pass the bins parameter an integer, which automatically creates that number of equal-width bins. Negative infinity and positive infinity objects are available in NumPy and ensure that all values get placed in a bin. If you have values that are outside of the bin edges, they will be made missing and not be placed in a bin.\n",
    "\n",
    "The cuts variable is now a Series of five ordered categories. It has all the normal Series methods and in step 3, the value_counts method is used to get a sense of its distribution.\n",
    "\n",
    "Very interestingly, pandas allows you to pass the groupby method any object. This means that you are able to form groups from something completely unrelated to the current DataFrame. Here, we group by the values in the cuts variable. For each grouping, we find the percentage of flights per airline with value_counts by setting normalize to True.\n",
    "\n",
    "Some interesting insights can be drawn from this result. Looking at the full result, SkyWest is the leading airline for under 200 miles but has no flights over 2,000 miles. In contrast, American Airlines has the fifth highest total for flights under 200 miles but has by far the most flights between 1,000 and 2,000 miles.\n",
    "\n",
    "### There's more...\n",
    "\n",
    "We can find more results when grouping by the cuts variable. For instance, we can find the 25th, 50th, and 75th percentile airtime for each distance grouping. As airtime is in minutes, we can divide by 60 to get hours:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumanth\\AppData\\Local\\Temp\\ipykernel_8552\\2062130766.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  flights.groupby(cuts)['AIR_TIME'].quantile(q=[.25, .5, .75]).div(60).round(2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DIST                  \n",
       "(-inf, 200.0]     0.25    0.43\n",
       "                  0.50    0.50\n",
       "                  0.75    0.57\n",
       "(200.0, 500.0]    0.25    0.77\n",
       "                  0.50    0.92\n",
       "                  0.75    1.05\n",
       "(500.0, 1000.0]   0.25    1.43\n",
       "                  0.50    1.65\n",
       "                  0.75    1.92\n",
       "(1000.0, 2000.0]  0.25    2.50\n",
       "                  0.50    2.93\n",
       "                  0.75    3.40\n",
       "(2000.0, inf]     0.25    4.30\n",
       "                  0.50    4.70\n",
       "                  0.75    5.03\n",
       "Name: AIR_TIME, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.groupby(cuts)['AIR_TIME'].quantile(q=[.25, .5, .75]).div(60).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this information to create informative string labels when using the cut function. These labels replace the interval notation. We can also chain the unstack method which transposes the inner index level to column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumanth\\AppData\\Local\\Temp\\ipykernel_8552\\4001547007.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  flights.groupby(cuts2)['AIRLINE'].value_counts(normalize=True).round(3).unstack().style.highlight_max(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7d172_row0_col9, #T_7d172_row1_col13, #T_7d172_row2_col3, #T_7d172_row3_col0, #T_7d172_row4_col10 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7d172\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >AIRLINE</th>\n",
       "      <th id=\"T_7d172_level0_col0\" class=\"col_heading level0 col0\" >AA</th>\n",
       "      <th id=\"T_7d172_level0_col1\" class=\"col_heading level0 col1\" >AS</th>\n",
       "      <th id=\"T_7d172_level0_col2\" class=\"col_heading level0 col2\" >B6</th>\n",
       "      <th id=\"T_7d172_level0_col3\" class=\"col_heading level0 col3\" >DL</th>\n",
       "      <th id=\"T_7d172_level0_col4\" class=\"col_heading level0 col4\" >EV</th>\n",
       "      <th id=\"T_7d172_level0_col5\" class=\"col_heading level0 col5\" >F9</th>\n",
       "      <th id=\"T_7d172_level0_col6\" class=\"col_heading level0 col6\" >HA</th>\n",
       "      <th id=\"T_7d172_level0_col7\" class=\"col_heading level0 col7\" >MQ</th>\n",
       "      <th id=\"T_7d172_level0_col8\" class=\"col_heading level0 col8\" >NK</th>\n",
       "      <th id=\"T_7d172_level0_col9\" class=\"col_heading level0 col9\" >OO</th>\n",
       "      <th id=\"T_7d172_level0_col10\" class=\"col_heading level0 col10\" >UA</th>\n",
       "      <th id=\"T_7d172_level0_col11\" class=\"col_heading level0 col11\" >US</th>\n",
       "      <th id=\"T_7d172_level0_col12\" class=\"col_heading level0 col12\" >VX</th>\n",
       "      <th id=\"T_7d172_level0_col13\" class=\"col_heading level0 col13\" >WN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >DIST</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "      <th class=\"blank col11\" >&nbsp;</th>\n",
       "      <th class=\"blank col12\" >&nbsp;</th>\n",
       "      <th class=\"blank col13\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7d172_level0_row0\" class=\"row_heading level0 row0\" >Under an Hour</th>\n",
       "      <td id=\"T_7d172_row0_col0\" class=\"data row0 col0\" >0.052000</td>\n",
       "      <td id=\"T_7d172_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_7d172_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
       "      <td id=\"T_7d172_row0_col3\" class=\"data row0 col3\" >0.086000</td>\n",
       "      <td id=\"T_7d172_row0_col4\" class=\"data row0 col4\" >0.289000</td>\n",
       "      <td id=\"T_7d172_row0_col5\" class=\"data row0 col5\" >0.000000</td>\n",
       "      <td id=\"T_7d172_row0_col6\" class=\"data row0 col6\" >0.000000</td>\n",
       "      <td id=\"T_7d172_row0_col7\" class=\"data row0 col7\" >0.211000</td>\n",
       "      <td id=\"T_7d172_row0_col8\" class=\"data row0 col8\" >0.000000</td>\n",
       "      <td id=\"T_7d172_row0_col9\" class=\"data row0 col9\" >0.326000</td>\n",
       "      <td id=\"T_7d172_row0_col10\" class=\"data row0 col10\" >0.027000</td>\n",
       "      <td id=\"T_7d172_row0_col11\" class=\"data row0 col11\" >0.000000</td>\n",
       "      <td id=\"T_7d172_row0_col12\" class=\"data row0 col12\" >0.000000</td>\n",
       "      <td id=\"T_7d172_row0_col13\" class=\"data row0 col13\" >0.009000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d172_level0_row1\" class=\"row_heading level0 row1\" >1 Hour</th>\n",
       "      <td id=\"T_7d172_row1_col0\" class=\"data row1 col0\" >0.071000</td>\n",
       "      <td id=\"T_7d172_row1_col1\" class=\"data row1 col1\" >0.001000</td>\n",
       "      <td id=\"T_7d172_row1_col2\" class=\"data row1 col2\" >0.007000</td>\n",
       "      <td id=\"T_7d172_row1_col3\" class=\"data row1 col3\" >0.189000</td>\n",
       "      <td id=\"T_7d172_row1_col4\" class=\"data row1 col4\" >0.156000</td>\n",
       "      <td id=\"T_7d172_row1_col5\" class=\"data row1 col5\" >0.005000</td>\n",
       "      <td id=\"T_7d172_row1_col6\" class=\"data row1 col6\" >0.000000</td>\n",
       "      <td id=\"T_7d172_row1_col7\" class=\"data row1 col7\" >0.100000</td>\n",
       "      <td id=\"T_7d172_row1_col8\" class=\"data row1 col8\" >0.012000</td>\n",
       "      <td id=\"T_7d172_row1_col9\" class=\"data row1 col9\" >0.159000</td>\n",
       "      <td id=\"T_7d172_row1_col10\" class=\"data row1 col10\" >0.062000</td>\n",
       "      <td id=\"T_7d172_row1_col11\" class=\"data row1 col11\" >0.016000</td>\n",
       "      <td id=\"T_7d172_row1_col12\" class=\"data row1 col12\" >0.028000</td>\n",
       "      <td id=\"T_7d172_row1_col13\" class=\"data row1 col13\" >0.194000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d172_level0_row2\" class=\"row_heading level0 row2\" >1-2 Hours</th>\n",
       "      <td id=\"T_7d172_row2_col0\" class=\"data row2 col0\" >0.144000</td>\n",
       "      <td id=\"T_7d172_row2_col1\" class=\"data row2 col1\" >0.023000</td>\n",
       "      <td id=\"T_7d172_row2_col2\" class=\"data row2 col2\" >0.003000</td>\n",
       "      <td id=\"T_7d172_row2_col3\" class=\"data row2 col3\" >0.206000</td>\n",
       "      <td id=\"T_7d172_row2_col4\" class=\"data row2 col4\" >0.101000</td>\n",
       "      <td id=\"T_7d172_row2_col5\" class=\"data row2 col5\" >0.038000</td>\n",
       "      <td id=\"T_7d172_row2_col6\" class=\"data row2 col6\" >0.000000</td>\n",
       "      <td id=\"T_7d172_row2_col7\" class=\"data row2 col7\" >0.051000</td>\n",
       "      <td id=\"T_7d172_row2_col8\" class=\"data row2 col8\" >0.030000</td>\n",
       "      <td id=\"T_7d172_row2_col9\" class=\"data row2 col9\" >0.106000</td>\n",
       "      <td id=\"T_7d172_row2_col10\" class=\"data row2 col10\" >0.131000</td>\n",
       "      <td id=\"T_7d172_row2_col11\" class=\"data row2 col11\" >0.025000</td>\n",
       "      <td id=\"T_7d172_row2_col12\" class=\"data row2 col12\" >0.004000</td>\n",
       "      <td id=\"T_7d172_row2_col13\" class=\"data row2 col13\" >0.138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d172_level0_row3\" class=\"row_heading level0 row3\" >2-4 Hours</th>\n",
       "      <td id=\"T_7d172_row3_col0\" class=\"data row3 col0\" >0.264000</td>\n",
       "      <td id=\"T_7d172_row3_col1\" class=\"data row3 col1\" >0.016000</td>\n",
       "      <td id=\"T_7d172_row3_col2\" class=\"data row3 col2\" >0.003000</td>\n",
       "      <td id=\"T_7d172_row3_col3\" class=\"data row3 col3\" >0.165000</td>\n",
       "      <td id=\"T_7d172_row3_col4\" class=\"data row3 col4\" >0.016000</td>\n",
       "      <td id=\"T_7d172_row3_col5\" class=\"data row3 col5\" >0.031000</td>\n",
       "      <td id=\"T_7d172_row3_col6\" class=\"data row3 col6\" >0.000000</td>\n",
       "      <td id=\"T_7d172_row3_col7\" class=\"data row3 col7\" >0.003000</td>\n",
       "      <td id=\"T_7d172_row3_col8\" class=\"data row3 col8\" >0.045000</td>\n",
       "      <td id=\"T_7d172_row3_col9\" class=\"data row3 col9\" >0.046000</td>\n",
       "      <td id=\"T_7d172_row3_col10\" class=\"data row3 col10\" >0.199000</td>\n",
       "      <td id=\"T_7d172_row3_col11\" class=\"data row3 col11\" >0.040000</td>\n",
       "      <td id=\"T_7d172_row3_col12\" class=\"data row3 col12\" >0.012000</td>\n",
       "      <td id=\"T_7d172_row3_col13\" class=\"data row3 col13\" >0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d172_level0_row4\" class=\"row_heading level0 row4\" >4+ Hours</th>\n",
       "      <td id=\"T_7d172_row4_col0\" class=\"data row4 col0\" >0.212000</td>\n",
       "      <td id=\"T_7d172_row4_col1\" class=\"data row4 col1\" >0.012000</td>\n",
       "      <td id=\"T_7d172_row4_col2\" class=\"data row4 col2\" >0.080000</td>\n",
       "      <td id=\"T_7d172_row4_col3\" class=\"data row4 col3\" >0.171000</td>\n",
       "      <td id=\"T_7d172_row4_col4\" class=\"data row4 col4\" >0.000000</td>\n",
       "      <td id=\"T_7d172_row4_col5\" class=\"data row4 col5\" >0.004000</td>\n",
       "      <td id=\"T_7d172_row4_col6\" class=\"data row4 col6\" >0.028000</td>\n",
       "      <td id=\"T_7d172_row4_col7\" class=\"data row4 col7\" >0.000000</td>\n",
       "      <td id=\"T_7d172_row4_col8\" class=\"data row4 col8\" >0.019000</td>\n",
       "      <td id=\"T_7d172_row4_col9\" class=\"data row4 col9\" >0.000000</td>\n",
       "      <td id=\"T_7d172_row4_col10\" class=\"data row4 col10\" >0.289000</td>\n",
       "      <td id=\"T_7d172_row4_col11\" class=\"data row4 col11\" >0.065000</td>\n",
       "      <td id=\"T_7d172_row4_col12\" class=\"data row4 col12\" >0.074000</td>\n",
       "      <td id=\"T_7d172_row4_col13\" class=\"data row4 col13\" >0.046000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d7f1a5e0e0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=['Under an Hour', '1 Hour', '1-2 Hours', '2-4 Hours', '4+ Hours']\n",
    "cuts2 = pd.cut(flights['DIST'], bins=bins, labels=labels)\n",
    "flights.groupby(cuts2)['AIRLINE'].value_counts(normalize=True).round(3).unstack().style.highlight_max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting the total number of flights between cities\n",
    "In the flights dataset, we have data on the origin and destination airport. It is trivial to count the number of flights originating in Houston and landing in Atlanta, for instance. What is more difficult is counting the total number of flights between the two cities, regardless of which one is the origin or destination.\n",
    "\n",
    "### Getting ready\n",
    "\n",
    "In this recipe, we count the total number of flights between two cities regardless of which one is the origin or destination. To accomplish this, we sort the origin and destination airports alphabetically so that each combination of airports always occurs in the same order. We can then use this new column arrangement to form groups and then to count.\n",
    "\n",
    "### How to do it...\n",
    "\n",
    "Read in the flights dataset, and find the total number of flights between each origin and destination airport:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>ORG_AIR</th>\n",
       "      <th>DEST_AIR</th>\n",
       "      <th>SCHED_DEP</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DIST</th>\n",
       "      <th>SCHED_ARR</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>SLC</td>\n",
       "      <td>1625</td>\n",
       "      <td>58.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>590</td>\n",
       "      <td>1905</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>UA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>IAD</td>\n",
       "      <td>823</td>\n",
       "      <td>7.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1452</td>\n",
       "      <td>1333</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>MQ</td>\n",
       "      <td>DFW</td>\n",
       "      <td>VPS</td>\n",
       "      <td>1305</td>\n",
       "      <td>36.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>641</td>\n",
       "      <td>1453</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>DCA</td>\n",
       "      <td>1555</td>\n",
       "      <td>7.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1192</td>\n",
       "      <td>1935</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1720</td>\n",
       "      <td>48.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1363</td>\n",
       "      <td>2225</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MONTH  DAY  WEEKDAY AIRLINE ORG_AIR DEST_AIR  SCHED_DEP  DEP_DELAY  \\\n",
       "0      1    1        4      WN     LAX      SLC       1625       58.0   \n",
       "1      1    1        4      UA     DEN      IAD        823        7.0   \n",
       "2      1    1        4      MQ     DFW      VPS       1305       36.0   \n",
       "3      1    1        4      AA     DFW      DCA       1555        7.0   \n",
       "4      1    1        4      WN     LAX      MCI       1720       48.0   \n",
       "\n",
       "   AIR_TIME  DIST  SCHED_ARR  ARR_DELAY  DIVERTED  CANCELLED  \n",
       "0      94.0   590       1905       65.0         0          0  \n",
       "1     154.0  1452       1333      -13.0         0          0  \n",
       "2      85.0   641       1453       35.0         0          0  \n",
       "3     126.0  1192       1935       -7.0         0          0  \n",
       "4     166.0  1363       2225       39.0         0          0  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights = pd.read_csv('data/flights.csv')\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORG_AIR  DEST_AIR\n",
       "ATL      ABE         31\n",
       "         ABQ         16\n",
       "         ABY         19\n",
       "         ACY          6\n",
       "         AEX         40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_count = flights.groupby(['ORG_AIR', 'DEST_AIR']).size()\n",
    "flights_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the total number of flights between Houston (IAH) and Atlanta (ATL) in both directions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORG_AIR  DEST_AIR\n",
       "ATL      IAH         121\n",
       "IAH      ATL         148\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_count.loc[[('ATL', 'IAH'), ('IAH', 'ATL')]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could simply sum these two numbers together to find the total flights between the cities but there is a more efficient and automated solution that can work for all flights. Let's independently sort the origin and destination cities for each row in alphabetical order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORG_AIR</th>\n",
       "      <th>DEST_AIR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>ABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>ABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL</td>\n",
       "      <td>ABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL</td>\n",
       "      <td>ABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL</td>\n",
       "      <td>ABE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ORG_AIR DEST_AIR\n",
       "0     ATL      ABE\n",
       "1     ATL      ABE\n",
       "2     ATL      ABE\n",
       "3     ATL      ABE\n",
       "4     ATL      ABE"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_sorted = flights[['ORG_AIR', 'DEST_AIR']].apply(sorted) #, axis=1\n",
    "flights_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that each row has been independently sorted, the column names are not correct. Let's rename them to something more generic and then again find the total number of flights between all cities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIR1  AIR2\n",
       "ATL   ABE      55\n",
       "      ABI      74\n",
       "      ABQ     343\n",
       "      ABR      19\n",
       "      ABY      19\n",
       "      ACT      49\n",
       "      ACV      40\n",
       "      ACY       9\n",
       "      AEX     109\n",
       "      AGS      83\n",
       "dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_count_ord = flights_sorted.rename(columns={'ORG_AIR':'AIR1', 'DEST_AIR':'AIR2'}) \\\n",
    "                                  .groupby(['AIR1', 'AIR2']) \\\n",
    "                                  .size()\n",
    "flights_count_ord.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select all the flights between Atlanta and Houston and verify that it matches the sum of the values in step 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "343"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_count_ord.loc[('ATL', 'ABQ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try and select flights with Houston followed by Atlanta, we get an error:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('ABQ', 'ATL')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ABQ'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mindex.pyx:842\u001b[0m, in \u001b[0;36mpandas._libs.index.BaseMultiIndexCodesEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ABQ'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\indexes\\multi.py:3105\u001b[0m, in \u001b[0;36mMultiIndex._get_loc_level\u001b[1;34m(self, key, level)\u001b[0m\n\u001b[0;32m   3104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   3106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:845\u001b[0m, in \u001b[0;36mpandas._libs.index.BaseMultiIndexCodesEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('ABQ', 'ATL')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mflights_count_ord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mABQ\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mATL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\indexing.py:1147\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\indexing.py:1330\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1329\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_ellipsis(tup)\n\u001b[1;32m-> 1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_lowerdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;66;03m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[0;32m   1333\u001b[0m tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\indexing.py:1031\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(ax0, MultiIndex)\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[38;5;66;03m#  is equivalent.\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;66;03m#  (see the other place where we call _handle_lowerdim_multi_index_axis0)\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m-> 1031\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LocIndexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_lowerdim_multi_index_axis0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1033\u001b[0m tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key_length(tup)\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tup):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\indexing.py:1356\u001b[0m, in \u001b[0;36m_LocIndexer._handle_lowerdim_multi_index_axis0\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1352\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ek:\n\u001b[0;32m   1353\u001b[0m     \u001b[38;5;66;03m# raise KeyError if number of indexers match\u001b[39;00m\n\u001b[0;32m   1354\u001b[0m     \u001b[38;5;66;03m# else IndexingError will be raised\u001b[39;00m\n\u001b[0;32m   1355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(tup) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnlevels:\n\u001b[1;32m-> 1356\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ek\n\u001b[0;32m   1357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo label returned\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mek\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\indexing.py:1350\u001b[0m, in \u001b[0;36m_LocIndexer._handle_lowerdim_multi_index_axis0\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1347\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1349\u001b[0m     \u001b[38;5;66;03m# fast path for series or for tup devoid of slices\u001b[39;00m\n\u001b[1;32m-> 1350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1352\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ek:\n\u001b[0;32m   1353\u001b[0m     \u001b[38;5;66;03m# raise KeyError if number of indexers match\u001b[39;00m\n\u001b[0;32m   1354\u001b[0m     \u001b[38;5;66;03m# else IndexingError will be raised\u001b[39;00m\n\u001b[0;32m   1355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(tup) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnlevels:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\indexing.py:1343\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[0;32m   1342\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\generic.py:4228\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4225\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m   4227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, MultiIndex):\n\u001b[1;32m-> 4228\u001b[0m     loc, new_index \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_loc_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m drop_level:\n\u001b[0;32m   4230\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_integer(loc):\n\u001b[0;32m   4231\u001b[0m             \u001b[38;5;66;03m# Slice index must be an integer or None\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stablediffusion\\lib\\site-packages\\pandas\\core\\indexes\\multi.py:3107\u001b[0m, in \u001b[0;36mMultiIndex._get_loc_level\u001b[1;34m(self, key, level)\u001b[0m\n\u001b[0;32m   3105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(key), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   3106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3108\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3109\u001b[0m     \u001b[38;5;66;03m# e.g. partial string indexing\u001b[39;00m\n\u001b[0;32m   3110\u001b[0m     \u001b[38;5;66;03m#  test_partial_string_timestamp_multiindex\u001b[39;00m\n\u001b[0;32m   3111\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('ABQ', 'ATL')"
     ]
    }
   ],
   "source": [
    "flights_count_ord.loc[('ABQ', 'ATL')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works...\n",
    "\n",
    "In step 1, we form groups by the origin and destination airport columns and then apply the size method to the groupby object, which simply returns the total number of rows for each group. Notice that we could have passed the string size to the agg method to achieve the same result. In step 2, the total number of flights for each direction between Atlanta and Houston are selected. The Series flights_count has a MultiIndex with two levels. One way to select rows from a MultiIndex is to pass the loc indexing operator a tuple of exact level values. Here, we actually select two different rows, ('ATL', 'HOU') and ('HOU', 'ATL'). We use a list of tuples to do this correctly.\n",
    "\n",
    "Step 3 is the most pertinent step in the recipe. We would like to have just one label for all flights between Atlanta and Houston and so far we have two. If we alphabetically sort each combination of origin and destination airports, we would then have a single label for flights between airports. To do this, we use the DataFrame apply method. This is different from the groupby apply method. No groups are formed in step 3.\n",
    "\n",
    "The DataFrame apply method must be passed a function. In this case, it's the built-in sorted function. By default, this function gets applied to each column as a Series. We can change the direction of computation by using axis=1 (or axis='index'). The sorted function has each row of data passed to it implicitly as a Series. It returns a list of sorted airport codes. Here is an example of passing the first row as a Series to the sorted function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LAX', 'SLC']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(flights.loc[0, ['ORG_AIR', 'DEST_AIR']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The apply method iterates over all rows using sorted in this exact manner. After completion of this operation, each row is independently sorted. The column names are now meaningless. We rename the column names in the next step and then perform the same grouping and aggregating as was done in step 2. This time, all flights between Atlanta and Houston fall under the same label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There's more...\n",
    "You might be wondering why we can't use the simpler sort_values Series method. This method does not sort independently and instead, preserves the row or column as a single record as one would expect while doing a data analysis. Step 3 is a very expensive operation and takes several seconds to complete. There are only about 60,000 rows so this solution would not scale well to larger data. Calling the\n",
    "\n",
    "Step 3 is a very expensive operation and takes several seconds to complete. There are only about 60,000 rows so this solution would not scale well to larger data. Calling the apply method with axis=1 is one of the least performant operations in all of pandas. Internally, pandas loops over each row and does not provide any speed boosts from NumPy. If possible, avoid using apply with axis=1.\n",
    "\n",
    "We can get a massive speed increase with the NumPy sort function. Let's go ahead and use this function and analyze its output. By default, it sorts each row independently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['LAX', 'SLC'],\n",
       "       ['DEN', 'IAD'],\n",
       "       ['DFW', 'VPS'],\n",
       "       ['DCA', 'DFW'],\n",
       "       ['LAX', 'MCI'],\n",
       "       ['IAH', 'SAN'],\n",
       "       ['DFW', 'MSY'],\n",
       "       ['PHX', 'SFO'],\n",
       "       ['ORD', 'STL'],\n",
       "       ['IAH', 'SJC']], dtype=object)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sorted = np.sort(flights[['ORG_AIR', 'DEST_AIR']])\n",
    "data_sorted[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A two-dimensional NumPy array is returned. NumPy does not easily do grouping operations so let's use the DataFrame constructor to create a new DataFrame and check whether it equals the flights_sorted DataFrame from step 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_sorted2 = pd.DataFrame(data_sorted, columns=['AIR1', 'AIR2'])\n",
    "flights_sorted2.equals(flights_sorted.rename(columns={'ORG_AIR':'AIR1', 'DEST_AIR':'AIR2'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the DataFrames are the same, you can replace step 3 with the previous faster sorting routine. Let's time the difference between each of the different sorting methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392 ms ± 33.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit flights_sorted = flights[['ORG_AIR', 'DEST_AIR']].apply(sorted, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.36 ms ± 343 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data_sorted = np.sort(flights[['ORG_AIR', 'DEST_AIR']])\n",
    "flights_sorted2 = pd.DataFrame(data_sorted, columns=['AIR1', 'AIR2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NumPy solution is an astounding 700 times faster than using apply with panda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the longest streak of on-time flights\n",
    "One of the most important metrics for airlines is their on-time flight performance. The Federal Aviation Administration considers a flight delayed when it arrives at least 15 minutes later than its scheduled arrival time. Pandas has direct methods to calculate the total and percentage of on-time flights per airline. While these basic summary statistics are an important metric, there are other non-trivial calculations that are interesting, such as finding the length of consecutive on-time flights for each airline at each of its origin airports.\n",
    "\n",
    "### Getting ready\n",
    "\n",
    "In this recipe, we find the longest consecutive streak of on-time flights for each airline at each origin airport. This requires each value in a column to be aware of the value immediately following it. We make clever use of the diff and cumsum methods in order to find streaks before applying this methodology to each of the groups.\n",
    "\n",
    "### How to do it...\n",
    "\n",
    "Before we get started with the actual flights dataset, let's practice counting streaks of ones with a small sample Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "5    1\n",
       "6    1\n",
       "7    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, 1, 1, 0, 1, 1, 1, 0])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final representation of the streaks of ones will be a Series of the same length as the original with an independent count beginning from one for each streak. To get started, let's use the cumsum method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    3\n",
       "4    4\n",
       "5    5\n",
       "6    6\n",
       "7    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = s.cumsum()\n",
    "s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now accumulated all the ones going down the Series. Let's multiply this Series by the original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    0\n",
       "4    4\n",
       "5    5\n",
       "6    6\n",
       "7    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.mul(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have only non-zero values where we originally had ones. This result is fairly close to what we desire. We just need to restart each streak at one instead of where the cumulative sum left off. Let's chain the diff method, which subtracts the previous value from the current:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    1.0\n",
       "2    1.0\n",
       "3   -3.0\n",
       "4    4.0\n",
       "5    1.0\n",
       "6    1.0\n",
       "7   -6.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.mul(s1).diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A negative value represents the end of a streak. We need to propagate the negative values down the Series and use them to subtract away the excess accumulation from step 2. To do this, we will make all non-negative values missing with the where method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    NaN\n",
       "2    NaN\n",
       "3   -3.0\n",
       "4    NaN\n",
       "5    NaN\n",
       "6    NaN\n",
       "7   -6.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.mul(s1).diff().where(lambda x: x < 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now propagate these values down with the ffill method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    NaN\n",
       "2    NaN\n",
       "3   -3.0\n",
       "4   -3.0\n",
       "5   -3.0\n",
       "6   -3.0\n",
       "7   -6.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.mul(s1).diff().where(lambda x: x < 0).ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can add this Series back to s1 to clear out the excess accumulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    2.0\n",
       "2    3.0\n",
       "3    0.0\n",
       "4    1.0\n",
       "5    2.0\n",
       "6    3.0\n",
       "7    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.mul(s1).diff().where(lambda x: x < 0).ffill().add(s1, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a working consecutive streak finder, we can find the longest streak per airline and origin airport. Let's read in the flights dataset and create a column to represent on-time arrival:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>ORG_AIR</th>\n",
       "      <th>ON_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MQ</td>\n",
       "      <td>DFW</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UA</td>\n",
       "      <td>IAH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F9</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UA</td>\n",
       "      <td>IAH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AIRLINE ORG_AIR  ON_TIME\n",
       "0      WN     LAX        0\n",
       "1      UA     DEN        1\n",
       "2      MQ     DFW        0\n",
       "3      AA     DFW        1\n",
       "4      WN     LAX        0\n",
       "5      UA     IAH        1\n",
       "6      AA     DFW        0\n",
       "7      F9     SFO        1\n",
       "8      AA     ORD        1\n",
       "9      UA     IAH        1"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights = pd.read_csv('data/flights.csv')\n",
    "flights['ON_TIME'] = flights['ARR_DELAY'].lt(15).astype(int)\n",
    "flights[['AIRLINE', 'ORG_AIR', 'ON_TIME']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use our logic from the first seven steps to define a function that returns the maximum streak of ones for a given Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_streak(s):\n",
    "    s1 = s.cumsum()\n",
    "    return s.mul(s1).diff().where(lambda x: x < 0) \\\n",
    "            .ffill().add(s1, fill_value=0).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the maximum streak of on-time arrivals per airline and origin airport along with the total number of flights and percentage of on-time arrivals. First, sort the day of the year and scheduled departure time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>size</th>\n",
       "      <th>max_streak</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>ORG_AIR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AA</th>\n",
       "      <th>ATL</th>\n",
       "      <td>0.82</td>\n",
       "      <td>233</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEN</th>\n",
       "      <td>0.74</td>\n",
       "      <td>219</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DFW</th>\n",
       "      <td>0.78</td>\n",
       "      <td>4006</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IAH</th>\n",
       "      <td>0.80</td>\n",
       "      <td>196</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAS</th>\n",
       "      <td>0.79</td>\n",
       "      <td>374</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean  size  max_streak\n",
       "AIRLINE ORG_AIR                        \n",
       "AA      ATL      0.82   233        15.0\n",
       "        DEN      0.74   219        17.0\n",
       "        DFW      0.78  4006        64.0\n",
       "        IAH      0.80   196        24.0\n",
       "        LAS      0.79   374        29.0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.sort_values(['MONTH', 'DAY', 'SCHED_DEP']) \\\n",
    "       .groupby(['AIRLINE', 'ORG_AIR'])['ON_TIME'] \\\n",
    "       .agg(['mean', 'size', max_streak]).round(2).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works...\n",
    "\n",
    "Finding streaks in the data is not a straightforward operation in pandas and requires methods that look ahead or behind, such as diff or shift, or those that remember their current state, such as cumsum. The final result from the first seven steps is a Series the same length as the original that keeps track of all consecutive ones. Throughout these steps, we use the mul and add methods instead of their operator equivalents (*) and (+). In my opinion, this allows for a slightly cleaner progression of calculations from left to right. You, of course, can replace these with the actual operators.\n",
    "\n",
    "Ideally, we would like to tell pandas to apply the cumsum method to the start of each streak and reset itself after the end of each one. It takes many steps to convey this message to pandas. Step 2 accumulates all the ones in the Series as a whole. The rest of the steps slowly remove any excess accumulation. In order to identify this excess accumulation, we need to find the end of each streak and subtract this value from the beginning of the next streak.\n",
    "\n",
    "To find the end of each streak, we cleverly make all values not part of the streak zero by multiplying s1 by the original Series of zeros and ones in step 3. The first zero following a non-zero, marks the end of a streak. That's good, but again, we need to eliminate the excess accumulation. Knowing where the streak ends doesn't exactly get us there.\n",
    "\n",
    "In step 4, we use the diff method to find this excess. The diff method takes the difference between the current value and any value located at a set number of rows away from it. By default, the difference between the current and the immediately preceding value is returned.\n",
    "\n",
    "Only negative values are meaningful in step 4. Those are the ones immediately following the end of a streak. These values need to be propagated down until the end of the following streak. To eliminate (make missing) all the values we don't care about, we use the where method, which takes a Series of conditionals of the same size as the calling Series. By default, all the True values remain the same, while the False values become missing. The where method allows you to use the calling Series as part of the conditional by taking a function as its first parameter. An anonymous function is used, which gets passed the calling Series implicitly and checks whether each value is less than zero. The result of step 5 is a Series where only the negative values are preserved with the rest changed to missing.\n",
    "\n",
    "The ffill method in step 6 replaces missing values with the last non-missing value going forward/down a Series. As the first three values don't follow a non-missing value, they remain missing. We finally have our Series that removes the excess accumulation. We add our accumulation Series to the result of step 6 to get the streaks all beginning from zero. The add method allows us to replace the missing values with the fill_value parameter. This completes the process of finding streaks of ones in the dataset. When doing complex logic like this, it is a good idea to use a small dataset where you know what the final output will be. It would be quite a difficult task to start at step 8 and build this streak-finding logic while grouping.\n",
    "\n",
    "In step 8, we create the ON_TIME column. One item of note is that the cancelled flights have missing values for ARR_DELAY, which do not pass the boolean condition and therefore result in a zero for the ON_TIME column. Canceled flights are treated the same as delayed.\n",
    "\n",
    "Step 9 turns our logic from the first seven steps into a function and chains the max method to return the longest streak. As our function returns a single value, it is formally an aggregating function and can be passed to the agg method as done in step 10. To ensure that we are looking at actual consecutive flights, we use the sort_values method to sort by date and scheduled departure time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
